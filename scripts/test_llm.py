"""
æµ‹è¯• LLM é…ç½®æ˜¯å¦æ­£ç¡®
"""
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from configs.settings import get_settings
from app.llm_provider import get_llm_provider


def test_llm_connection():
    """æµ‹è¯• LLM è¿æ¥"""
    print("=" * 60)
    print("ğŸ§ª LifeOS LLM é…ç½®æµ‹è¯•")
    print("=" * 60)
    
    settings = get_settings()
    
    print(f"\nğŸ“‹ å½“å‰é…ç½®:")
    print(f"   LLM æä¾›è€…: {settings.LLM_PROVIDER}")
    
    if settings.LLM_PROVIDER == "openai":
        print(f"   æ¨¡å‹: {settings.OPENAI_MODEL}")
        print(f"   API Key: {'å·²è®¾ç½®' if settings.OPENAI_API_KEY else 'âŒ æœªè®¾ç½®'}")
        if settings.OPENAI_BASE_URL:
            print(f"   Base URL: {settings.OPENAI_BASE_URL}")
    elif settings.LLM_PROVIDER == "hunyuan":
        print(f"   æ¨¡å‹: {settings.HUNYUAN_MODEL}")
        print(f"   Secret ID: {'å·²è®¾ç½®' if settings.TENCENT_SECRET_ID else 'âŒ æœªè®¾ç½®'}")
        print(f"   Secret Key: {'å·²è®¾ç½®' if settings.TENCENT_SECRET_KEY else 'âŒ æœªè®¾ç½®'}")
    
    print("\nğŸ”Œ æ­£åœ¨åˆå§‹åŒ– LLM æä¾›è€…...")
    
    try:
        # æ„å»ºå‚æ•°
        llm_kwargs = {}
        
        if settings.LLM_PROVIDER == "openai":
            llm_kwargs = {
                "api_key": settings.OPENAI_API_KEY,
                "model": settings.OPENAI_MODEL
            }
            if settings.OPENAI_BASE_URL:
                llm_kwargs["base_url"] = settings.OPENAI_BASE_URL
        elif settings.LLM_PROVIDER == "hunyuan":
            llm_kwargs = {
                "secret_id": settings.TENCENT_SECRET_ID,
                "secret_key": settings.TENCENT_SECRET_KEY,
                "model": settings.HUNYUAN_MODEL
            }
        
        llm = get_llm_provider(
            provider_type=settings.LLM_PROVIDER,
            **llm_kwargs
        )
        
        print("âœ… LLM æä¾›è€…åˆå§‹åŒ–æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ LLM æä¾›è€…åˆå§‹åŒ–å¤±è´¥: {e}")
        print("\nğŸ’¡ è¯·æ£€æŸ¥:")
        print("   1. .env æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        print("   2. API Key æ˜¯å¦æ­£ç¡®é…ç½®")
        print("   3. ç›¸å…³ä¾èµ–æ˜¯å¦å·²å®‰è£…")
        return False
    
    print("\nğŸ“¤ æ­£åœ¨å‘é€æµ‹è¯•è¯·æ±‚...")
    
    try:
        test_messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„ AI åŠ©æ‰‹ã€‚"},
            {"role": "user", "content": "è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"}
        ]
        
        response = llm.chat(test_messages, temperature=0.7, max_tokens=100)
        
        print("âœ… æµ‹è¯•è¯·æ±‚æˆåŠŸ")
        print(f"\nğŸ“ AI å“åº”:\n{response}\n")
        
        print("=" * 60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼LLM é…ç½®æ­£ç¡®ã€‚")
        print("=" * 60)
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¯·æ±‚å¤±è´¥: {e}")
        print("\nğŸ’¡ å¯èƒ½çš„åŸå› :")
        print("   1. API Key æ— æ•ˆæˆ–å·²è¿‡æœŸ")
        print("   2. è´¦æˆ·ä½™é¢ä¸è¶³")
        print("   3. ç½‘ç»œè¿æ¥é—®é¢˜")
        print("   4. API æœåŠ¡æš‚æ—¶ä¸å¯ç”¨")
        return False


def main():
    """ä¸»å‡½æ•°"""
    success = test_llm_connection()
    
    if not success:
        print("\nâŒ æµ‹è¯•å¤±è´¥ã€‚è¯·å‚è€ƒ DEPLOYMENT_GUIDE.md è¿›è¡Œé…ç½®ã€‚")
        sys.exit(1)
    else:
        print("\nâœ… å¯ä»¥å¼€å§‹ä½¿ç”¨ LifeOS äº†ï¼")
        print("   è¿è¡Œ: python run.py")
        sys.exit(0)


if __name__ == "__main__":
    main()
