"""
LifeOS å®Œæ•´å®ç° - æ¥å…¥çœŸå®å¤§æ¨¡å‹
å±•ç¤º 3 å¤§æ ¸å¿ƒèƒ½åŠ›ï¼šä¿¡æ¯è¿‡è½½å¤„ç†ã€è®¡åˆ’æ‹†è§£ã€ä¸ªæ€§åŒ–æŒ‡å¯¼
"""

import os
import json
from typing import Dict, List, Optional
from datetime import datetime
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from modules.conversation_flow import (
    ConversationFlowManager,
    ConversationMode,
    ConversationState
)
from modules.smart_summary import (
    SmartSummaryParser,
    build_smart_summary_prompt
)
from modules.next_action import (
    NextActionParser,
    build_next_action_prompt,
    adjust_suggestions_by_preferences,
    UserPreferences
)
from modules.memory import (
    MemoryStore,
    MemoryManager,
    MemoryType
)
from modules.system_prompts import (
    get_system_prompt,
    add_memory_context
)
from modules.llm_service import call_llm, init_llm_service


class LifeOSRealAssistant:
    """LifeOS çœŸå®åŠ©æ‰‹ï¼ˆæ¥å…¥çœŸå® LLMï¼‰"""
    
    def __init__(self, db_path: str = "lifeos_data.db", llm_provider: str = None):
        """åˆå§‹åŒ–"""
        # åˆå§‹åŒ– LLM
        if llm_provider is None:
            llm_provider = os.getenv("LLM_PROVIDER", "mock")
        
        print(f"ğŸš€ åˆå§‹åŒ– LifeOSï¼ˆLLM æä¾›è€…: {llm_provider}ï¼‰")
        init_llm_service(llm_provider)
        
        # åˆå§‹åŒ–å„æ¨¡å—
        self.flow_manager = ConversationFlowManager()
        self.summary_parser = SmartSummaryParser()
        self.action_parser = NextActionParser()
        
        # åˆå§‹åŒ–è®°å¿†æ¨¡å—
        memory_store = MemoryStore(db_path)
        self.memory_manager = MemoryManager(memory_store)
        
        # å¯¹è¯çŠ¶æ€ç¼“å­˜
        self.conversation_states: Dict[str, ConversationState] = {}
        
        print("âœ… LifeOS åˆå§‹åŒ–å®Œæˆ\n")
    
    def chat(self, user_id: str, user_input: str) -> Dict:
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥ï¼ˆçœŸå® LLM ç‰ˆæœ¬ï¼‰
        
        Args:
            user_id: ç”¨æˆ· ID
            user_input: ç”¨æˆ·è¾“å…¥
            
        Returns:
            å“åº”å­—å…¸
        """
        try:
            print(f"\n{'='*60}")
            print(f"ç”¨æˆ·è¾“å…¥: {user_input}")
            print(f"{'='*60}\n")
            
            # 1. è·å–æˆ–åˆ›å»ºå¯¹è¯çŠ¶æ€
            state = self.conversation_states.get(user_id)
            
            # 2. è·¯ç”±åˆ°åˆé€‚çš„æ¨¡å¼
            mode, classification, response_suggestion = self.flow_manager.route(
                user_input, 
                state
            )
            
            print(f"ğŸ“Š æ£€æµ‹åˆ°æ¨¡å¼: {mode.value}")
            print(f"ğŸ“Š æ„å›¾ç±»å‹: {classification.intent.value}")
            print(f"ğŸ“Š ç½®ä¿¡åº¦: {classification.confidence:.2f}\n")
            
            # 3. æ ¹æ®æ¨¡å¼å¤„ç†
            if mode == ConversationMode.EMOTION_SUPPORT:
                return self._handle_emotion_mode(user_id, user_input, response_suggestion)
            
            elif mode == ConversationMode.ACTION_ASSISTANT:
                return self._handle_action_mode(user_id, user_input, classification)
            
            elif mode == ConversationMode.MIXED:
                return self._handle_mixed_mode(user_id, user_input, response_suggestion)
            
            else:  # UNKNOWN
                return self._handle_unknown(user_id, response_suggestion)
        
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            
            return {
                "success": False,
                "error": str(e),
                "fallback_message": "æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ã€‚èƒ½å†è¯´ä¸€æ¬¡å—ï¼Ÿ"
            }
    
    def _handle_emotion_mode(
        self, 
        user_id: str, 
        user_input: str, 
        response_suggestion: str
    ) -> Dict:
        """å¤„ç†æƒ…ç»ªæ”¯æŒæ¨¡å¼ï¼ˆä½¿ç”¨é¢„è®¾å“åº”ï¼Œä¸è°ƒç”¨ LLMï¼‰"""
        print("ğŸ’š è¿›å…¥æƒ…ç»ªæ”¯æŒæ¨¡å¼\n")
        
        return {
            "success": True,
            "mode": "emotion_support",
            "response_type": "text",
            "content": {
                "text": response_suggestion,
                "options": [
                    {"label": "ğŸŒ¿ è¯´è¯´è¯", "action": "continue_emotion"},
                    {"label": "ğŸ“‹ å¸®æˆ‘æ•´ç†ä»»åŠ¡", "action": "switch_to_action"}
                ]
            },
            "display_text": response_suggestion,
            "timestamp": datetime.now().isoformat()
        }
    
    def _handle_action_mode(
        self, 
        user_id: str, 
        user_input: str,
        classification
    ) -> Dict:
        """å¤„ç†è¡ŒåŠ¨åŠ©ç†æ¨¡å¼ï¼ˆè°ƒç”¨çœŸå® LLMï¼‰"""
        print("ğŸ“‹ è¿›å…¥è¡ŒåŠ¨åŠ©ç†æ¨¡å¼")
        
        # åˆ¤æ–­æ˜¯æ‘˜è¦è¿˜æ˜¯æ‹†è§£
        if any(keyword in user_input for keyword in ["ä»»åŠ¡", "è¦åš", "äº‹æƒ…", "ä»Šå¤©", "æ¸…å•"]):
            print("â†’ ç”Ÿæˆæ™ºèƒ½æ‘˜è¦\n")
            return self._generate_summary_real(user_id, user_input)
        else:
            print("â†’ ç”Ÿæˆä»»åŠ¡æ‹†è§£\n")
            return self._generate_action_plan_real(user_id, user_input)
    
    def _handle_mixed_mode(
        self, 
        user_id: str, 
        user_input: str, 
        response_suggestion: str
    ) -> Dict:
        """å¤„ç†æ··åˆæ¨¡å¼"""
        print("ğŸ”„ è¿›å…¥æ··åˆæ¨¡å¼ï¼ˆæƒ…ç»ª+ä»»åŠ¡ï¼‰\n")
        
        return {
            "success": True,
            "mode": "mixed",
            "response_type": "text",
            "content": {
                "text": response_suggestion,
                "quick_actions": [
                    {"label": "å…ˆæ”¾æ¾ä¸€ä¸‹", "action": "relax"},
                    {"label": "ç›´æ¥æ•´ç†ä»»åŠ¡", "action": "organize_tasks"}
                ]
            },
            "display_text": response_suggestion,
            "timestamp": datetime.now().isoformat()
        }
    
    def _handle_unknown(self, user_id: str, response_suggestion: str) -> Dict:
        """å¤„ç†æœªçŸ¥æƒ…å†µ"""
        print("â“ è¿›å…¥æ¾„æ¸…æ¨¡å¼\n")
        
        return {
            "success": True,
            "mode": "clarification",
            "response_type": "text",
            "content": {
                "text": response_suggestion
            },
            "display_text": response_suggestion,
            "timestamp": datetime.now().isoformat()
        }
    
    def _generate_summary_real(self, user_id: str, user_input: str) -> Dict:
        """ç”Ÿæˆæ™ºèƒ½æ‘˜è¦ï¼ˆçœŸå® LLMï¼‰"""
        print("ğŸ¤– è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦...")
        
        try:
            # æ„å»º prompt
            messages = build_smart_summary_prompt(user_input, include_examples=True)
            
            # è·å–ç”¨æˆ·åå¥½
            profile = self.memory_manager.get_user_profile(user_id)
            user_memories = {
                "morning_productivity": profile.morning_productivity,
                "prefers_short_tasks": profile.prefers_short_tasks,
                "long_term_goals": profile.long_term_goals
            }
            
            # æ·»åŠ è®°å¿†ä¸Šä¸‹æ–‡
            if user_memories.get("morning_productivity") or user_memories.get("long_term_goals"):
                messages[0]["content"] = add_memory_context(messages[0]["content"], user_memories)
            
            # è°ƒç”¨ LLM
            llm_response = call_llm(messages, temperature=0.7, max_tokens=1500)
            print(f"âœ… LLM å“åº”æˆåŠŸ ({len(llm_response)} å­—ç¬¦)\n")
            
            # è§£æå“åº”
            result = self.summary_parser.parse_llm_response(llm_response, user_input)
            
            if result:
                formatted_text = self.summary_parser.format_for_display(result)
                
                return {
                    "success": True,
                    "mode": "action_assistant",
                    "response_type": "summary_card",
                    "content": {
                        "summary": result.one_line_summary,
                        "categories": result.categories,
                        "highlights": result.highlights,
                        "priorities": [
                            {
                                "item": p.item,
                                "importance": p.importance,
                                "urgency": p.urgency,
                                "reason": p.reason
                            }
                            for p in result.priority_assessment
                        ],
                        "suggested_action": {
                            "desc": result.suggested_next_action.desc,
                            "est_minutes": result.suggested_next_action.est_minutes,
                            "next_step": result.suggested_next_action.next_step
                        },
                        "skip_candidates": result.skip_candidates
                    },
                    "display_text": formatted_text,
                    "timestamp": datetime.now().isoformat()
                }
            else:
                return {
                    "success": False,
                    "error": "æ— æ³•è§£æ LLM å“åº”"
                }
        
        except Exception as e:
            print(f"âŒ LLM è°ƒç”¨å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def _generate_action_plan_real(self, user_id: str, user_input: str) -> Dict:
        """ç”Ÿæˆä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’ï¼ˆçœŸå® LLMï¼‰"""
        print("ğŸ¤– è°ƒç”¨ LLM ç”Ÿæˆè¡ŒåŠ¨è®¡åˆ’...")
        
        try:
            # æ„å»º prompt
            messages = build_next_action_prompt(user_input, include_examples=True)
            
            # è°ƒç”¨ LLM
            llm_response = call_llm(messages, temperature=0.7, max_tokens=1500)
            print(f"âœ… LLM å“åº”æˆåŠŸ ({len(llm_response)} å­—ç¬¦)\n")
            
            # è§£æå“åº”
            result = self.action_parser.parse_llm_response(llm_response)
            
            if result:
                # æ ¹æ®ç”¨æˆ·åå¥½è°ƒæ•´
                prefs = UserPreferences(
                    morning_productivity=True,
                    prefers_short_tasks=True
                )
                adjusted_result = adjust_suggestions_by_preferences(result, prefs)
                
                formatted_text = self.action_parser.format_for_display(adjusted_result)
                
                return {
                    "success": True,
                    "mode": "action_assistant",
                    "response_type": "action_plan",
                    "content": {
                        "task": adjusted_result.task,
                        "actions": [
                            {
                                "desc": action.desc,
                                "est_minutes": action.est_minutes,
                                "type": action.type.value,
                                "difficulty": action.difficulty,
                                "expected_outcome": action.expected_outcome
                            }
                            for action in adjusted_result.candidate_actions
                        ],
                        "recommended_index": adjusted_result.recommended_action_index,
                        "rationale": adjusted_result.rationale
                    },
                    "display_text": formatted_text,
                    "timestamp": datetime.now().isoformat()
                }
            else:
                return {
                    "success": False,
                    "error": "æ— æ³•è§£æ LLM å“åº”"
                }
        
        except Exception as e:
            print(f"âŒ LLM è°ƒç”¨å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }


# ============================================================================
# Demo åœºæ™¯
# ============================================================================

def demo_scenario_1():
    """Demo #1: ä¿¡æ¯è¿‡è½½åœºæ™¯"""
    print("\n" + "="*80)
    print("ğŸ“º Demo #1: ä¿¡æ¯è¿‡è½½ â†’ è‡ªåŠ¨æ€»ç»“ä¸æç‚¼é‡ç‚¹")
    print("="*80)
    
    assistant = LifeOSRealAssistant(llm_provider=os.getenv("LLM_PROVIDER", "mock"))
    
    user_input = """æˆ‘æ„Ÿè§‰å¥½å´©æºƒï¼Œä»Šå¤©äº‹æƒ…å¤ªå¤šäº†ï¼š
    1. æ˜å¤©è¦äº¤çš„é¡¹ç›®æŠ¥å‘Šè¿˜æ²¡å†™å®Œ
    2. æ™šä¸Šè¦å’Œå®¢æˆ·å¼€ä¼šï¼Œè¿˜æ²¡å‡†å¤‡ææ–™
    3. æœ‰ä¸‰å°é‚®ä»¶è¦å›å¤
    4. åŒäº‹è®©æˆ‘å¸®å¿™çœ‹ä¸¤ä¸ªæ–‡ä»¶
    5. è¿˜è¦å»è¶…å¸‚ä¹°èœ
    
    æˆ‘éƒ½ä¸çŸ¥é“ä»å“ªé‡Œå¼€å§‹ï¼Œè„‘å­ä¸€å›¢ä¹±"""
    
    response = assistant.chat("demo_user_001", user_input)
    
    if response["success"]:
        print("\n" + "="*80)
        print("ğŸ¤– LifeOS åŠ©ç†è¾“å‡ºï¼ˆå±•ç¤º 3 å¤§è§£å†³ç—›ç‚¹ï¼‰")
        print("="*80)
        print("\nâ‘  ä¿¡æ¯è¿‡è½½ â†’ è‡ªåŠ¨æ€»ç»“ä¸æç‚¼é‡ç‚¹\n")
        print(response["display_text"])
    else:
        print(f"\nâŒ é”™è¯¯: {response.get('error')}")


def demo_scenario_2():
    """Demo #2: è®¡åˆ’éš¾æ‰§è¡Œåœºæ™¯"""
    print("\n" + "="*80)
    print("ğŸ“º Demo #2: è®¡åˆ’éš¾æ‰§è¡Œ â†’ è‡ªåŠ¨æ‹†æˆä¸‹ä¸€æ­¥è¡ŒåŠ¨")
    print("="*80)
    
    assistant = LifeOSRealAssistant(llm_provider=os.getenv("LLM_PROVIDER", "mock"))
    
    user_input = "æˆ‘æƒ³å¼€å§‹å­¦ä¹  Python æ•°æ®åˆ†æï¼Œä½†ä¸çŸ¥é“ä»å“ªé‡Œå¼€å§‹"
    
    response = assistant.chat("demo_user_002", user_input)
    
    if response["success"]:
        print("\n" + "="*80)
        print("ğŸ¤– LifeOS åŠ©ç†è¾“å‡º")
        print("="*80)
        print("\nâ‘¡ è®¡åˆ’éš¾æ‰§è¡Œ â†’ è‡ªåŠ¨æ‹†æˆ\"ä¸‹ä¸€æ­¥è¡ŒåŠ¨\"\n")
        print(response["display_text"])
    else:
        print(f"\nâŒ é”™è¯¯: {response.get('error')}")


def demo_scenario_3():
    """Demo #3: ä¸ªæ€§åŒ–æŒ‡å¯¼åœºæ™¯"""
    print("\n" + "="*80)
    print("ğŸ“º Demo #3: ä¸ªæ€§åŒ–æŒ‡å¯¼ â†’ æ ¹æ®ç”¨æˆ·ä¹ æƒ¯è°ƒæ•´è®¡åˆ’")
    print("="*80)
    
    assistant = LifeOSRealAssistant(llm_provider=os.getenv("LLM_PROVIDER", "mock"))
    
    # å…ˆè®¾ç½®ç”¨æˆ·åå¥½
    assistant.memory_manager.remember(
        "demo_user_003",
        "evening_productivity",
        False,  # æ™šä¸Šæ•ˆç‡ä½
        MemoryType.PREFERENCE
    )
    assistant.memory_manager.remember(
        "demo_user_003",
        "morning_productivity",
        True,  # æ—©ä¸Šæ•ˆç‡é«˜
        MemoryType.PREFERENCE
    )
    
    user_input = "ä»Šå¤©ä¸‹åˆè¦å†™æŠ¥å‘Šï¼Œæ™šä¸Šè¦å›é‚®ä»¶ï¼Œæ˜å¤©ä¸Šåˆè¦å¼€ä¼š"
    
    response = assistant.chat("demo_user_003", user_input)
    
    if response["success"]:
        print("\n" + "="*80)
        print("ğŸ¤– LifeOS åŠ©ç†è¾“å‡º")
        print("="*80)
        print("\nâ‘¢ ä¸ªæ€§åŒ–æŒ‡å¯¼ â†’ æ ¹æ®ä½ ä»¥å¾€ä¹ æƒ¯è°ƒæ•´è®¡åˆ’\n")
        print(response["display_text"])
        print("\nğŸ’¡ ä¸ªæ€§åŒ–å»ºè®®ï¼š")
        print("ï¼ˆåŸºäºä½ ä¹‹å‰å‘Šè¯‰æˆ‘ï¼šä½ æ—©ä¸Šæ•ˆç‡é«˜ã€æ™šä¸Šæ•ˆç‡ä½ï¼‰")
        print("'æˆ‘æŠŠéœ€è¦æ·±åº¦æ€è€ƒçš„æŠ¥å‘Šå®‰æ’åœ¨æ˜å¤©ä¸Šåˆï¼Œ")
        print(" æŠŠç®€å•çš„é‚®ä»¶å›å¤ç•™åœ¨ä»Šå¤©ä¸‹åˆå¤„ç†ã€‚'")
    else:
        print(f"\nâŒ é”™è¯¯: {response.get('error')}")


def run_all_demos():
    """è¿è¡Œæ‰€æœ‰ Demo"""
    print("\n" + "ğŸ¬"*40)
    print("LifeOS å®Œæ•´ Demo æ¼”ç¤º")
    print("å±•ç¤º 3 å¤§æ ¸å¿ƒèƒ½åŠ›ï¼šä¿¡æ¯è¿‡è½½å¤„ç†ã€è®¡åˆ’æ‹†è§£ã€ä¸ªæ€§åŒ–æŒ‡å¯¼")
    print("ğŸ¬"*40)
    
    demo_scenario_1()
    input("\næŒ‰å›è½¦ç»§ç»­ä¸‹ä¸€ä¸ª Demo...")
    
    demo_scenario_2()
    input("\næŒ‰å›è½¦ç»§ç»­ä¸‹ä¸€ä¸ª Demo...")
    
    demo_scenario_3()
    
    print("\n" + "="*80)
    print("âœ… æ‰€æœ‰ Demo æ¼”ç¤ºå®Œæˆï¼")
    print("="*80)


if __name__ == "__main__":
    run_all_demos()
