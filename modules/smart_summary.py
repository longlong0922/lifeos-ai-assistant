"""
æ™ºèƒ½æ‘˜è¦æ¨¡å— (Smart Summary Module)
ç”¨äºŽå¤„ç†ä¿¡æ¯è¿‡è½½ï¼šæŽ¥æ”¶ç”¨æˆ·çš„æ‚ä¹±ä»»åŠ¡/æƒ³æ³•ï¼Œè¿”å›žç»“æž„åŒ–æ‘˜è¦

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ä¸€å¥è¯æ€»ç»“
2. è‡ªåŠ¨åˆ†ç±»
3. æå–é‡ç‚¹
4. ä¼˜å…ˆçº§åˆ¤æ–­ï¼ˆé‡è¦æ€§ + ç´§æ€¥æ€§ï¼‰
5. ç”Ÿæˆä¸‹ä¸€æ­¥å»ºè®®
"""

import json
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from datetime import datetime


@dataclass
class PriorityItem:
    """ä¼˜å…ˆçº§é¡¹"""
    item: str
    importance: int  # 0-10
    urgency: int     # 0-10
    reason: str = ""


@dataclass
class QuickAction:
    """å¿«é€Ÿè¡ŒåŠ¨"""
    desc: str
    est_minutes: int
    next_step: str
    type: str = "immediate"  # immediate | prep | calendar


@dataclass
class SummaryResult:
    """æ‘˜è¦ç»“æžœ"""
    one_line_summary: str
    categories: List[str]
    highlights: List[str]
    priority_assessment: List[PriorityItem]
    skip_candidates: List[str]
    one_hour_actions: List[QuickAction]
    suggested_next_action: QuickAction
    confidence: float
    raw_input: str
    created_at: str


# ============================================================================
# System Promptï¼ˆå¯ç›´æŽ¥ç”¨äºŽ LLM APIï¼‰
# ============================================================================

SMART_SUMMARY_SYSTEM_PROMPT = """ä½ æ˜¯ LifeOS çš„æ™ºèƒ½æ‘˜è¦åŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·å¤„ç†ä¿¡æ¯è¿‡è½½ã€‚

## ä½ çš„ä»»åŠ¡
æŽ¥æ”¶ç”¨æˆ·è¾“å…¥çš„æ‚ä¹±ä»»åŠ¡ã€æƒ³æ³•æˆ–è®¡åˆ’ï¼Œè¾“å‡ºä¸€ä¸ªç»“æž„åŒ–çš„ JSON æ‘˜è¦ã€‚

## è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼éµå®ˆ JSON Schemaï¼‰
{
  "one_line_summary": "ç”¨ä¸€å¥è¯æ¦‚æ‹¬ç”¨æˆ·çš„æ•´ä½“æƒ…å†µï¼ˆ20å­—ä»¥å†…ï¼‰",
  "categories": ["work", "personal", "urgent", "health", ...],
  "highlights": ["æœ€é‡è¦çš„ç‚¹1", "æœ€é‡è¦çš„ç‚¹2", ...],
  "priority_assessment": [
    {"item": "ä»»åŠ¡å", "importance": 0-10, "urgency": 0-10, "reason": "ç®€çŸ­åŽŸå› "}
  ],
  "skip_candidates": ["å¯ä»¥è·³è¿‡æˆ–æŽ¨è¿Ÿçš„äº‹é¡¹"],
  "one_hour_actions": [
    {"desc": "1å°æ—¶å†…å¯åšçš„åŠ¨ä½œ", "est_minutes": X, "next_step": "å…·ä½“ä¸‹ä¸€æ­¥", "type": "immediate"}
  ],
  "suggested_next_action": {
    "desc": "æœ€æŽ¨èçš„ç¬¬ä¸€æ­¥",
    "est_minutes": X,
    "next_step": "å…·ä½“æ“ä½œ",
    "type": "immediate"
  },
  "confidence": 0.0-1.0
}

## æ ¸å¿ƒåŽŸåˆ™
1. **ä¼˜å…ˆçº§åˆ¤æ–­**ï¼šé‡è¦æ€§(importance) > ç´§æ€¥æ€§(urgency)
2. **ä½Žæ‘©æ“¦å¯åŠ¨**ï¼šä¼˜å…ˆæŽ¨èèƒ½åœ¨ 1-5 åˆ†é’Ÿå†…å®Œæˆçš„åŠ¨ä½œ
3. **å¿ƒç†å‡è´Ÿ**ï¼šå½“ç”¨æˆ·è¡¨è¾¾ç–²æƒ«æ—¶ï¼ŒæŽ¨èèƒ½å¿«é€Ÿå®Œæˆä¸”æ˜¾è‘—é™ä½Žç„¦è™‘çš„åŠ¨ä½œ
4. **å…·ä½“å¯æ‰§è¡Œ**ï¼šæ¯ä¸ª next_step å¿…é¡»æ˜¯æ˜Žç¡®çš„ã€å¯ç«‹å³æ‰§è¡Œçš„åŠ¨ä½œ

## åˆ†ç±»æ ‡å‡†
- work: å·¥ä½œç›¸å…³
- personal: ä¸ªäººç”Ÿæ´»
- urgent: æœ‰æ˜Žç¡®æˆªæ­¢æ—¶é—´
- health: å¥åº·ç›¸å…³
- finance: è´¢åŠ¡ç›¸å…³
- social: ç¤¾äº¤ç›¸å…³
- learning: å­¦ä¹ æˆé•¿

## æ—¶é—´ä¼°ç®—æ ‡å‡†
- 1åˆ†é’Ÿï¼šæ”¯ä»˜ã€å‘é€ç®€çŸ­æ¶ˆæ¯ã€ç¡®è®¤ä¿¡æ¯
- 5åˆ†é’Ÿï¼šåˆ—è¦ç‚¹ã€æ•´ç†æ¸…å•ã€å¿«é€Ÿå›žå¤
- 15åˆ†é’Ÿï¼šå‡†å¤‡ææ–™ã€åˆæ­¥ç ”ç©¶
- 30åˆ†é’Ÿä»¥ä¸Šï¼šæ·±åº¦å·¥ä½œã€ä¼šè®®

è¾“å‡ºå¿…é¡»æ˜¯å¯è§£æžçš„ JSONï¼Œä¸è¦åŒ…å«ä»»ä½•é¢å¤–çš„æ–‡å­—è¯´æ˜Žã€‚
"""


# ============================================================================
# Few-Shot Examplesï¼ˆä¾› LLM å­¦ä¹ ï¼‰
# ============================================================================

FEW_SHOT_EXAMPLES = [
    {
        "user_input": "ä»Šå¤©è¦åš7ä»¶äº‹ï¼šå†™æŠ¥å‘ŠAã€ç­”å¤é‚®ä»¶ã€å‡†å¤‡æ˜Žå¤©ä¼šè®®ã€ä»˜æˆ¿ç§Ÿã€ä¹°èœã€æ´—è¡£æœã€æ‰“ç”µè¯ç»™å¦ˆå¦ˆã€‚æˆ‘ç´¯äº†ï¼Œä¸çŸ¥é“å…ˆåšå“ªä¸ªã€‚",
        "assistant_output": {
            "one_line_summary": "ç”¨æˆ·æœ‰7ä»¶ä»»åŠ¡ï¼Œæ„Ÿåˆ°ç–²æƒ«ä¸”æ— æ³•ä¼˜å…ˆæŽ’åº",
            "categories": ["work", "personal", "urgent", "finance"],
            "highlights": [
                "æŠ¥å‘ŠAéœ€è¦é«˜é›†ä¸­åº¦æ—¶é—´",
                "ä»˜æˆ¿ç§Ÿæœ‰æˆªæ­¢æ—¶é—´ï¼ˆä»Šå¤©ï¼‰",
                "ç”¨æˆ·è¡¨è¾¾ç–²æƒ«ï¼Œéœ€è¦ä½Žæ‘©æ“¦å¯åŠ¨"
            ],
            "priority_assessment": [
                {"item": "ä»˜æˆ¿ç§Ÿ", "importance": 9, "urgency": 9, "reason": "æˆªæ­¢æ—¶é—´ä»Šå¤©ï¼Œé¿å…æ»žçº³é‡‘"},
                {"item": "å†™æŠ¥å‘ŠA", "importance": 10, "urgency": 7, "reason": "æ˜Žå¤©æˆªæ­¢ï¼Œéœ€æ·±åº¦å·¥ä½œ"},
                {"item": "å‡†å¤‡æ˜Žå¤©ä¼šè®®", "importance": 8, "urgency": 8, "reason": "æ˜Žå¤©å°±è¦ç”¨"},
                {"item": "æ‰“ç”µè¯ç»™å¦ˆå¦ˆ", "importance": 7, "urgency": 3, "reason": "æƒ…æ„Ÿç»´ç³»é‡è¦ä½†ä¸ç´§æ€¥"},
                {"item": "ç­”å¤é‚®ä»¶", "importance": 6, "urgency": 5, "reason": "å–å†³äºŽé‚®ä»¶å†…å®¹"},
                {"item": "ä¹°èœ", "importance": 5, "urgency": 4, "reason": "å¯æŽ¨è¿Ÿåˆ°æ™šä¸Šæˆ–æ˜Žå¤©"},
                {"item": "æ´—è¡£æœ", "importance": 4, "urgency": 3, "reason": "å¯æŽ¨è¿Ÿ"}
            ],
            "skip_candidates": ["æ´—è¡£æœï¼ˆå¯æŽ¨åˆ°æ˜Žå¤©ï¼‰", "ä¹°èœï¼ˆå¯ç®€åŒ–ä¸ºå¤–å–ï¼‰"],
            "one_hour_actions": [
                {
                    "desc": "ä»˜æˆ¿ç§Ÿ",
                    "est_minutes": 2,
                    "next_step": "æ‰“å¼€é“¶è¡ŒAPPï¼Œé€‰æ‹©æˆ¿ç§Ÿè½¬è´¦",
                    "type": "immediate"
                },
                {
                    "desc": "åˆ—å‡ºæŠ¥å‘ŠAçš„3ä¸ªæ ¸å¿ƒè¦ç‚¹",
                    "est_minutes": 5,
                    "next_step": "æ‰“å¼€æ–‡æ¡£ï¼Œç”¨5åˆ†é’Ÿåˆ—å‡ºæ¡†æž¶",
                    "type": "prep"
                }
            ],
            "suggested_next_action": {
                "desc": "å…ˆä»˜æˆ¿ç§Ÿï¼ˆ1åˆ†é’Ÿå®Œæˆï¼‰",
                "est_minutes": 2,
                "next_step": "æ‰“å¼€æ‰‹æœºé“¶è¡ŒAPPï¼Œå®Œæˆè½¬è´¦",
                "type": "immediate"
            },
            "confidence": 0.95
        }
    },
    {
        "user_input": "æ„Ÿè§‰åŽ‹åŠ›å¥½å¤§ï¼Œæ˜Žå¤©è¦é¢è¯•ï¼Œä»Šå¤©è¿˜è¦å‡†å¤‡ææ–™ï¼Œä¸‹åˆè¿˜æœ‰ä¸ªä¼šã€‚",
        "assistant_output": {
            "one_line_summary": "ç”¨æˆ·é¢ä¸´é¢è¯•åŽ‹åŠ›ï¼Œå½“å¤©ä»»åŠ¡è¾ƒå¤š",
            "categories": ["work", "urgent"],
            "highlights": [
                "æ˜Žå¤©é¢è¯•æ˜¯æ ¸å¿ƒåŽ‹åŠ›æº",
                "å‡†å¤‡ææ–™æ˜¯å½“å¤©æœ€é‡è¦ä»»åŠ¡",
                "ä¸‹åˆæœ‰ä¼šè®®ï¼Œæ—¶é—´ç´§å¼ "
            ],
            "priority_assessment": [
                {"item": "å‡†å¤‡é¢è¯•ææ–™", "importance": 10, "urgency": 10, "reason": "æ˜Žå¤©é¢è¯•ï¼Œä»Šå¤©å¿…é¡»å®Œæˆ"},
                {"item": "ä¸‹åˆä¼šè®®", "importance": 7, "urgency": 8, "reason": "å·²å®šæ—¶é—´ï¼Œå¿…é¡»å‚åŠ "}
            ],
            "skip_candidates": [],
            "one_hour_actions": [
                {
                    "desc": "åˆ—å‡ºé¢è¯•å¯èƒ½è¢«é—®åˆ°çš„3ä¸ªé—®é¢˜",
                    "est_minutes": 10,
                    "next_step": "æ‰“å¼€ç¬”è®°æœ¬ï¼Œå›žå¿†å²—ä½éœ€æ±‚ï¼Œå†™ä¸‹3ä¸ªæ ¸å¿ƒé—®é¢˜",
                    "type": "prep"
                },
                {
                    "desc": "å‡†å¤‡è‡ªæˆ‘ä»‹ç»ï¼ˆ1åˆ†é’Ÿç‰ˆæœ¬ï¼‰",
                    "est_minutes": 15,
                    "next_step": "å¯¹ç€é•œå­ç»ƒä¹ 3éï¼Œè®¡æ—¶ç¡®ä¿åœ¨1åˆ†é’Ÿå†…",
                    "type": "immediate"
                }
            ],
            "suggested_next_action": {
                "desc": "å…ˆç”¨5åˆ†é’Ÿæ·±å‘¼å¸æ”¾æ¾ï¼Œç„¶åŽåˆ—å‡ºé¢è¯•3ä¸ªé—®é¢˜",
                "est_minutes": 5,
                "next_step": "è®¾ç½®5åˆ†é’Ÿè®¡æ—¶å™¨ï¼Œä¸“æ³¨æ·±å‘¼å¸",
                "type": "immediate"
            },
            "confidence": 0.92
        }
    },
    {
        "user_input": "ä»Šå¤©å°±æƒ³ä¼‘æ¯ï¼Œä½†è¿˜æœ‰ç‚¹æ‚äº‹ï¼šå›žä¸ªæ¶ˆæ¯ã€æ•´ç†æ¡Œé¢ã€å¯èƒ½è¦ä¹°ç‚¹ä¸œè¥¿ã€‚",
        "assistant_output": {
            "one_line_summary": "ç”¨æˆ·æƒ³ä¼‘æ¯ï¼Œåªæœ‰å°‘é‡ä½Žä¼˜å…ˆçº§ä»»åŠ¡",
            "categories": ["personal"],
            "highlights": [
                "ç”¨æˆ·æ˜Žç¡®è¡¨è¾¾æƒ³ä¼‘æ¯",
                "ä»»åŠ¡éƒ½æ˜¯å¯æŽ¨è¿Ÿçš„æ‚äº‹"
            ],
            "priority_assessment": [
                {"item": "å›žæ¶ˆæ¯", "importance": 5, "urgency": 4, "reason": "å–å†³äºŽæ¶ˆæ¯å†…å®¹ï¼Œå¤§å¤šå¯æŽ¨è¿Ÿ"},
                {"item": "æ•´ç†æ¡Œé¢", "importance": 3, "urgency": 2, "reason": "å¯éšæ—¶åš"},
                {"item": "ä¹°ä¸œè¥¿", "importance": 4, "urgency": 3, "reason": "ä¸ç´§æ€¥ï¼Œå¯æ˜Žå¤©"}
            ],
            "skip_candidates": ["æ•´ç†æ¡Œé¢ï¼ˆå¯ä»¥æ˜Žå¤©ï¼‰", "ä¹°ä¸œè¥¿ï¼ˆå¯ä»¥æ˜Žå¤©æˆ–ç½‘è´­ï¼‰"],
            "one_hour_actions": [
                {
                    "desc": "å¿«é€Ÿæµè§ˆæ¶ˆæ¯ï¼Œåªå›žå¤ç´§æ€¥çš„",
                    "est_minutes": 3,
                    "next_step": "æ‰“å¼€æ‰‹æœºï¼Œè®¾ç½®3åˆ†é’Ÿè®¡æ—¶ï¼Œåªå›žå¤æ ‡è®°ä¸ºç´§æ€¥çš„",
                    "type": "immediate"
                }
            ],
            "suggested_next_action": {
                "desc": "ç”¨1åˆ†é’Ÿå¿«é€Ÿå›žå¤æœ€é‡è¦çš„æ¶ˆæ¯ï¼Œç„¶åŽåŽ»ä¼‘æ¯",
                "est_minutes": 1,
                "next_step": "æ‰“å¼€æ¶ˆæ¯åˆ—è¡¨ï¼Œåªå›žå¤ç¬¬ä¸€æ¡ï¼Œå…¶ä»–æ˜Žå¤©å†è¯´",
                "type": "immediate"
            },
            "confidence": 0.88
        }
    }
]


# ============================================================================
# è§£æžå™¨ä¸Žè¾…åŠ©å‡½æ•°
# ============================================================================

class SmartSummaryParser:
    """æ™ºèƒ½æ‘˜è¦è§£æžå™¨"""
    
    @staticmethod
    def parse_llm_response(response_text: str, user_input: str) -> Optional[SummaryResult]:
        """
        è§£æž LLM è¿”å›žçš„ JSON å“åº”
        
        Args:
            response_text: LLM è¿”å›žçš„æ–‡æœ¬
            user_input: ç”¨æˆ·åŽŸå§‹è¾“å…¥
            
        Returns:
            SummaryResult å¯¹è±¡ï¼Œæˆ– Noneï¼ˆå¦‚æžœè§£æžå¤±è´¥ï¼‰
        """
        try:
            # å°è¯•æå– JSONï¼ˆå¤„ç†å¯èƒ½åŒ…å« markdown ä»£ç å—çš„æƒ…å†µï¼‰
            json_text = response_text.strip()
            if json_text.startswith("```json"):
                json_text = json_text[7:]
            if json_text.startswith("```"):
                json_text = json_text[3:]
            if json_text.endswith("```"):
                json_text = json_text[:-3]
            json_text = json_text.strip()
            
            data = json.loads(json_text)
            
            # æž„å»º PriorityItem åˆ—è¡¨
            priority_items = [
                PriorityItem(
                    item=p.get("item", ""),
                    importance=p.get("importance", 5),
                    urgency=p.get("urgency", 5),
                    reason=p.get("reason", "")
                )
                for p in data.get("priority_assessment", [])
            ]
            
            # æž„å»º QuickAction åˆ—è¡¨
            one_hour_actions = [
                QuickAction(
                    desc=a.get("desc", ""),
                    est_minutes=a.get("est_minutes", 5),
                    next_step=a.get("next_step", ""),
                    type=a.get("type", "immediate")
                )
                for a in data.get("one_hour_actions", [])
            ]
            
            # æž„å»ºæŽ¨èåŠ¨ä½œ
            suggested = data.get("suggested_next_action", {})
            suggested_action = QuickAction(
                desc=suggested.get("desc", ""),
                est_minutes=suggested.get("est_minutes", 5),
                next_step=suggested.get("next_step", ""),
                type=suggested.get("type", "immediate")
            )
            
            return SummaryResult(
                one_line_summary=data.get("one_line_summary", ""),
                categories=data.get("categories", []),
                highlights=data.get("highlights", []),
                priority_assessment=priority_items,
                skip_candidates=data.get("skip_candidates", []),
                one_hour_actions=one_hour_actions,
                suggested_next_action=suggested_action,
                confidence=data.get("confidence", 0.8),
                raw_input=user_input,
                created_at=datetime.now().isoformat()
            )
            
        except (json.JSONDecodeError, KeyError, TypeError) as e:
            print(f"è§£æžé”™è¯¯: {e}")
            return None
    
    @staticmethod
    def to_json(summary: SummaryResult) -> str:
        """å°† SummaryResult è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²"""
        def convert(obj):
            if hasattr(obj, '__dict__'):
                return obj.__dict__
            return obj
        
        return json.dumps(asdict(summary), ensure_ascii=False, indent=2)
    
    @staticmethod
    def format_for_display(summary: SummaryResult) -> str:
        """æ ¼å¼åŒ–ä¸ºäººç±»å¯è¯»çš„æ˜¾ç¤ºæ–‡æœ¬"""
        lines = [
            f"ðŸ“‹ {summary.one_line_summary}",
            "",
            f"ðŸ·ï¸ åˆ†ç±»: {', '.join(summary.categories)}",
            "",
            "âœ¨ é‡ç‚¹:",
        ]
        for h in summary.highlights:
            lines.append(f"  â€¢ {h}")
        
        lines.append("")
        lines.append("âš¡ ä¼˜å…ˆçº§æŽ’åº:")
        for p in sorted(summary.priority_assessment, 
                       key=lambda x: (x.importance + x.urgency), 
                       reverse=True)[:5]:
            lines.append(f"  {p.item} [é‡è¦:{p.importance} ç´§æ€¥:{p.urgency}]")
            if p.reason:
                lines.append(f"    â†’ {p.reason}")
        
        if summary.skip_candidates:
            lines.append("")
            lines.append("â¸ï¸ å¯æŽ¨è¿Ÿ:")
            for s in summary.skip_candidates:
                lines.append(f"  â€¢ {s}")
        
        lines.append("")
        lines.append(f"ðŸŽ¯ å»ºè®®ä¸‹ä¸€æ­¥: {summary.suggested_next_action.desc}")
        lines.append(f"   é¢„è®¡æ—¶é—´: {summary.suggested_next_action.est_minutes}åˆ†é’Ÿ")
        lines.append(f"   å…·ä½“æ“ä½œ: {summary.suggested_next_action.next_step}")
        
        return "\n".join(lines)


# ============================================================================
# æž„å»ºå®Œæ•´ Prompt çš„è¾…åŠ©å‡½æ•°
# ============================================================================

def build_smart_summary_prompt(user_input: str, include_examples: bool = True) -> List[Dict[str, str]]:
    """
    æž„å»ºå®Œæ•´çš„ LLM promptï¼ˆmessages æ ¼å¼ï¼‰
    
    Args:
        user_input: ç”¨æˆ·è¾“å…¥
        include_examples: æ˜¯å¦åŒ…å« few-shot ç¤ºä¾‹
        
    Returns:
        messages åˆ—è¡¨ï¼ˆé€‚ç”¨äºŽ OpenAI API ç­‰ï¼‰
    """
    messages = [
        {"role": "system", "content": SMART_SUMMARY_SYSTEM_PROMPT}
    ]
    
    if include_examples:
        for example in FEW_SHOT_EXAMPLES:
            messages.append({"role": "user", "content": example["user_input"]})
            messages.append({
                "role": "assistant", 
                "content": json.dumps(example["assistant_output"], ensure_ascii=False, indent=2)
            })
    
    messages.append({"role": "user", "content": user_input})
    
    return messages


# ============================================================================
# æµ‹è¯•ä¸Žç¤ºä¾‹
# ============================================================================

if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šæ¨¡æ‹Ÿ LLM å“åº”
    test_input = "ä»Šå¤©è¦å¤„ç†é¡¹ç›®æ–‡æ¡£ã€å¼€ä¼šã€è¿˜è¦åŽ»å–å¿«é€’ï¼Œæ„Ÿè§‰æœ‰ç‚¹ä¹±ã€‚"
    
    # æ¨¡æ‹Ÿçš„ LLM å“åº”ï¼ˆå®žé™…åº”è¯¥è°ƒç”¨ LLM APIï¼‰
    mock_response = """```json
{
  "one_line_summary": "ç”¨æˆ·æœ‰3ä»¶äº‹å¾…åŠžï¼Œæ„Ÿè§‰æ··ä¹±",
  "categories": ["work", "personal"],
  "highlights": [
    "é¡¹ç›®æ–‡æ¡£å¯èƒ½éœ€è¦é›†ä¸­æ—¶é—´",
    "å–å¿«é€’æ˜¯ä½Žæ‘©æ“¦ä»»åŠ¡"
  ],
  "priority_assessment": [
    {"item": "é¡¹ç›®æ–‡æ¡£", "importance": 8, "urgency": 7, "reason": "å·¥ä½œç›¸å…³ï¼Œéœ€è¦å®Œæˆ"},
    {"item": "å¼€ä¼š", "importance": 7, "urgency": 8, "reason": "å·²å®šæ—¶é—´"},
    {"item": "å–å¿«é€’", "importance": 4, "urgency": 5, "reason": "å¯éšæ—¶å–"}
  ],
  "skip_candidates": [],
  "one_hour_actions": [
    {
      "desc": "å…ˆåŽ»å–å¿«é€’ï¼ˆ10åˆ†é’Ÿï¼‰",
      "est_minutes": 10,
      "next_step": "ä¸‹æ¥¼åˆ°å¿«é€’æŸœå–ä»¶",
      "type": "immediate"
    },
    {
      "desc": "åˆ—å‡ºé¡¹ç›®æ–‡æ¡£çš„3ä¸ªç« èŠ‚",
      "est_minutes": 5,
      "next_step": "æ‰“å¼€æ–‡æ¡£ï¼Œå†™ä¸‹å¤§çº²",
      "type": "prep"
    }
  ],
  "suggested_next_action": {
    "desc": "å…ˆå–å¿«é€’ï¼ˆ10åˆ†é’Ÿè½»æ¾å®Œæˆï¼‰",
    "est_minutes": 10,
    "next_step": "ä¸‹æ¥¼åˆ°å¿«é€’æŸœï¼Œé¡ºä¾¿æ´»åŠ¨ä¸€ä¸‹",
    "type": "immediate"
  },
  "confidence": 0.85
}
```"""
    
    # è§£æž
    parser = SmartSummaryParser()
    result = parser.parse_llm_response(mock_response, test_input)
    
    if result:
        print("âœ… è§£æžæˆåŠŸï¼\n")
        print(parser.format_for_display(result))
        print("\n" + "="*50)
        print("\nðŸ“„ JSON è¾“å‡º:")
        print(parser.to_json(result))
    else:
        print("âŒ è§£æžå¤±è´¥")
    
    # æ˜¾ç¤ºå¦‚ä½•æž„å»º prompt
    print("\n" + "="*50)
    print("\nðŸ“ æž„å»ºçš„ Prompt Messages:")
    messages = build_smart_summary_prompt(test_input, include_examples=False)
    for i, msg in enumerate(messages):
        print(f"\n[{i}] {msg['role'].upper()}:")
        print(msg['content'][:200] + "..." if len(msg['content']) > 200 else msg['content'])
