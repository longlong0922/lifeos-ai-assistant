"""
æ™®é€šèŠå¤©èŠ‚ç‚¹
"""
from typing import Dict
from app.models import GraphState, ChatMessage
from app.llm_provider import BaseLLMProvider, LIFE_OS_SYSTEM_PROMPT


def chat_node(state: GraphState, llm: BaseLLMProvider) -> Dict:
    """
    æ™®é€šèŠå¤©èŠ‚ç‚¹ï¼šå¤„ç†ä¸€èˆ¬æ€§å¯¹è¯
    """
    user_message = state.messages[-1].content
    
    # æ„å»ºå¯¹è¯å†å²
    messages = [{"role": "system", "content": LIFE_OS_SYSTEM_PROMPT}]
    
    # æ·»åŠ æœ€è¿‘çš„å¯¹è¯å†å²ï¼ˆæœ€å¤š 10 æ¡ï¼‰
    for msg in state.messages[-10:]:
        messages.append({
            "role": "user" if msg.role == "user" else "assistant",
            "content": msg.content
        })
    
    # è°ƒç”¨ LLM
    response = llm.chat(messages, temperature=0.8, max_tokens=800)
    
    # æ·»åŠ å¿«æ·å»ºè®®
    suggestions = [
        "ğŸ¯ æŸ¥çœ‹ä»Šæ—¥ç®€æŠ¥",
        "ğŸ“Š è®°å½•ä¹ æƒ¯",
        "ğŸ’­ æ·±åº¦åæ€",
        "ğŸ”® åšä¸ªå†³ç­–"
    ]
    
    state.messages.append(ChatMessage(
        role="assistant",
        content=response,
        metadata={"suggestions": suggestions}
    ))
    
    return {"messages": state.messages, "next_node": None}
