"""
LangGraph å·¥ä½œæµ - å®Œæ•´çš„æ™ºèƒ½ä½“æ‰§è¡Œæµç¨‹
ä½¿ç”¨çŠ¶æ€å›¾ç®¡ç†æ•´ä¸ªå¯¹è¯æµ
"""

import json
import os
from typing import Dict, Any, List
from datetime import datetime

from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

from .state import AgentState
from .prompts import (
    intent_recognition_prompt,
    task_extraction_prompt,
    task_analysis_prompt,
    priority_sorting_prompt,
    action_decomposition_prompt,
    personalization_prompt,
    final_output_prompt,
)
from .tools import get_all_tools


class LifeOSWorkflow:
    """
    LifeOS å®Œæ•´å·¥ä½œæµ
    
    æµç¨‹ï¼š
    1. æ„å›¾è¯†åˆ« â†’ åˆ¤æ–­ç”¨æˆ·éœ€æ±‚ç±»å‹
    2. ä»»åŠ¡æå– â†’ ä»è¾“å…¥ä¸­æå–æ‰€æœ‰ä»»åŠ¡
    3. ä»»åŠ¡åˆ†æ â†’ è¯„ä¼°æ¯ä¸ªä»»åŠ¡çš„å±æ€§
    4. ä¼˜å…ˆçº§æ’åº â†’ åˆ†ä¸ºé«˜/ä¸­/ä½ä¼˜å…ˆçº§
    5. è¡ŒåŠ¨æ‹†è§£ â†’ æ¨èä»»åŠ¡æ‹†æˆå°æ­¥éª¤
    6. ä¸ªæ€§åŒ–è°ƒæ•´ â†’ æ ¹æ®ç”¨æˆ·ä¹ æƒ¯è°ƒæ•´
    7. è¾“å‡ºç”Ÿæˆ â†’ ç”Ÿæˆæœ€ç»ˆå‹å¥½çš„æ¶ˆæ¯
    """
    
    def __init__(
        self,
        llm_provider: str = "hunyuan",
        db_path: str = "lifeos_data.db"
    ):
        """
        åˆå§‹åŒ–å·¥ä½œæµ
        
        Args:
            llm_provider: LLM æä¾›è€… (hunyuan/openai/mock)
            db_path: æ•°æ®åº“è·¯å¾„
        """
        # åˆå§‹åŒ– LLM
        self.llm = self._init_llm(llm_provider)
        
        # åˆå§‹åŒ–å·¥å…·
        self.tools = get_all_tools(db_path)
        
        # æ„å»ºå·¥ä½œæµå›¾
        self.workflow = self._build_workflow()
        
        # ç¼–è¯‘ä¸ºå¯æ‰§è¡Œåº”ç”¨
        self.app = self.workflow.compile()
    
    def _init_llm(self, provider: str) -> ChatOpenAI:
        """åˆå§‹åŒ– LLM"""
        if provider == "hunyuan":
            return ChatOpenAI(
                api_key=os.getenv("TENCENT_SECRET_KEY"),
                base_url="https://api.hunyuan.cloud.tencent.com/v1",
                model=os.getenv("HUNYUAN_MODEL", "hunyuan-large"),
                temperature=0.7
            )
        elif provider == "openai":
            return ChatOpenAI(
                api_key=os.getenv("OPENAI_API_KEY"),
                model=os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
                temperature=0.7
            )
        else:
            # Mock mode - ä½¿ç”¨å‡çš„ LLM
            return None
    
    def _build_workflow(self) -> StateGraph:
        """æ„å»º LangGraph å·¥ä½œæµ"""
        
        # åˆ›å»ºçŠ¶æ€å›¾
        workflow = StateGraph(AgentState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("intent_recognition", self._intent_recognition_node)
        workflow.add_node("task_extraction", self._task_extraction_node)
        workflow.add_node("task_analysis", self._task_analysis_node)
        workflow.add_node("priority_sorting", self._priority_sorting_node)
        workflow.add_node("action_decomposition", self._action_decomposition_node)
        workflow.add_node("personalization", self._personalization_node)
        workflow.add_node("output_generation", self._output_generation_node)
        workflow.add_node("emotion_support", self._emotion_support_node)
        
        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("intent_recognition")
        
        # æ·»åŠ æ¡ä»¶è¾¹
        workflow.add_conditional_edges(
            "intent_recognition",
            self._route_by_intent,
            {
                "task": "task_extraction",
                "emotion": "emotion_support",
                "mixed": "task_extraction",
                "unknown": "emotion_support"
            }
        )
        
        # ä»»åŠ¡å¤„ç†æµç¨‹
        workflow.add_edge("task_extraction", "task_analysis")
        workflow.add_edge("task_analysis", "priority_sorting")
        workflow.add_edge("priority_sorting", "action_decomposition")
        workflow.add_edge("action_decomposition", "personalization")
        workflow.add_edge("personalization", "output_generation")
        
        # ç»“æŸèŠ‚ç‚¹
        workflow.add_edge("output_generation", END)
        workflow.add_edge("emotion_support", END)
        
        return workflow
    
    # =========================================================================
    # èŠ‚ç‚¹å‡½æ•°
    # =========================================================================
    
    def _intent_recognition_node(self, state: AgentState) -> Dict[str, Any]:
        """èŠ‚ç‚¹1: æ„å›¾è¯†åˆ«"""
        print("ğŸ” [èŠ‚ç‚¹1] æ„å›¾è¯†åˆ«ä¸­...")
        
        user_input = state["user_input"]
        
        if self.llm:
            # ä½¿ç”¨ LLM è¯†åˆ«æ„å›¾
            prompt = intent_recognition_prompt.format(user_input=user_input)
            response = self.llm.invoke([HumanMessage(content=prompt)])
            
            try:
                result = json.loads(response.content)
                intent = result.get("intent", "unknown")
                confidence = result.get("confidence", 0.5)
                reasoning = result.get("reasoning", "")
            except:
                intent = "unknown"
                confidence = 0.3
                reasoning = "è§£æå¤±è´¥"
        else:
            # Mock æ¨¡å¼ - ç®€å•è§„åˆ™
            user_lower = user_input.lower()
            if any(k in user_lower for k in ['ç´¯', 'ç„¦è™‘', 'å‹åŠ›', 'å´©æºƒ']):
                if any(k in user_lower for k in ['ä»»åŠ¡', 'è¦åš', 'å®Œæˆ']):
                    intent = "mixed"
                    confidence = 0.85
                else:
                    intent = "emotion"
                    confidence = 0.9
            elif any(k in user_lower for k in ['ä»»åŠ¡', 'è¦åš', 'æ•´ç†', 'å®‰æ’']):
                intent = "task"
                confidence = 0.9
            else:
                intent = "unknown"
                confidence = 0.4
            reasoning = "åŸºäºå…³é”®è¯åŒ¹é…"
        
        print(f"   âœ“ æ„å›¾: {intent} (ç½®ä¿¡åº¦: {confidence:.2f})")
        
        return {
            "intent": intent,
            "intent_confidence": confidence,
            "processing_steps": [f"æ„å›¾è¯†åˆ«: {intent} ({reasoning})"],
            "should_continue": True
        }
    
    def _task_extraction_node(self, state: AgentState) -> Dict[str, Any]:
        """èŠ‚ç‚¹2: ä»»åŠ¡æå–"""
        print("ğŸ“ [èŠ‚ç‚¹2] æå–ä»»åŠ¡ä¸­...")
        
        user_input = state["user_input"]
        
        if self.llm:
            prompt = task_extraction_prompt.format(user_input=user_input)
            response = self.llm.invoke([HumanMessage(content=prompt)])
            
            try:
                tasks = json.loads(response.content)
            except:
                # ç®€å•æ‹†åˆ†
                tasks = [line.strip() for line in user_input.split('\n') if line.strip()]
        else:
            # Mock - ç®€å•æ‹†åˆ†
            tasks = []
            for line in user_input.split('\n'):
                line = line.strip()
                if line and any(char.isalnum() for char in line):
                    # ç§»é™¤æ•°å­—åºå·
                    import re
                    cleaned = re.sub(r'^\d+[\.\)ã€]?\s*', '', line)
                    if cleaned:
                        tasks.append(cleaned)
        
        print(f"   âœ“ æå–åˆ° {len(tasks)} ä¸ªä»»åŠ¡")
        for i, task in enumerate(tasks, 1):
            print(f"      {i}. {task[:50]}...")
        
        return {
            "raw_tasks": tasks,
            "processing_steps": [f"ä»»åŠ¡æå–: æ‰¾åˆ° {len(tasks)} ä¸ªä»»åŠ¡"]
        }
    
    def _task_analysis_node(self, state: AgentState) -> Dict[str, Any]:
        """èŠ‚ç‚¹3: ä»»åŠ¡åˆ†æ"""
        print("ğŸ”¬ [èŠ‚ç‚¹3] åˆ†æä»»åŠ¡å±æ€§...")
        
        tasks = state["raw_tasks"]
        
        # ä½¿ç”¨ä»»åŠ¡åˆ†æå·¥å…·
        task_analyzer = self.tools[0]  # TaskAnalysisTool
        
        result_json = task_analyzer._run(
            tasks=tasks,
            user_context=state.get("user_context", {})
        )
        
        analyzed_tasks = json.loads(result_json)
        
        print(f"   âœ“ åˆ†æå®Œæˆ")
        for task in analyzed_tasks[:3]:
            print(f"      â€¢ {task['description'][:40]}")
            print(f"        é‡è¦æ€§: {task['importance']}/10, ç´§æ€¥æ€§: {task['urgency']}/10")
        
        return {
            "analyzed_tasks": analyzed_tasks,
            "processing_steps": [f"ä»»åŠ¡åˆ†æ: è¯„ä¼°äº† {len(analyzed_tasks)} ä¸ªä»»åŠ¡"]
        }
    
    def _priority_sorting_node(self, state: AgentState) -> Dict[str, Any]:
        """èŠ‚ç‚¹4: ä¼˜å…ˆçº§æ’åº"""
        print("ğŸ“Š [èŠ‚ç‚¹4] ä¼˜å…ˆçº§æ’åº...")
        
        analyzed_tasks = state["analyzed_tasks"]
        
        # æŒ‰ä¼˜å…ˆçº§åˆ†ç±»
        high_priority = []
        medium_priority = []
        low_priority = []
        deferrable = []
        
        for task in analyzed_tasks:
            importance = task["importance"]
            urgency = task["urgency"]
            
            if (importance >= 7 and urgency >= 7) or urgency >= 9:
                high_priority.append(task)
            elif (importance >= 6 and urgency >= 5) or importance >= 8:
                medium_priority.append(task)
            else:
                low_priority.append(task)
            
            if task["can_defer"]:
                deferrable.append(task["description"])
        
        print(f"   âœ“ é«˜ä¼˜å…ˆçº§: {len(high_priority)} ä¸ª")
        print(f"   âœ“ ä¸­ä¼˜å…ˆçº§: {len(medium_priority)} ä¸ª")
        print(f"   âœ“ ä½ä¼˜å…ˆçº§: {len(low_priority)} ä¸ª")
        print(f"   âœ“ å¯å»¶å: {len(deferrable)} ä¸ª")
        
        return {
            "high_priority": high_priority,
            "medium_priority": medium_priority,
            "low_priority": low_priority,
            "deferrable": deferrable,
            "processing_steps": [f"ä¼˜å…ˆçº§æ’åº: é«˜{len(high_priority)}/ä¸­{len(medium_priority)}/ä½{len(low_priority)}"]
        }
    
    def _action_decomposition_node(self, state: AgentState) -> Dict[str, Any]:
        """èŠ‚ç‚¹5: è¡ŒåŠ¨æ‹†è§£"""
        print("ğŸ”§ [èŠ‚ç‚¹5] æ‹†è§£è¡ŒåŠ¨æ­¥éª¤...")
        
        high_priority = state["high_priority"]
        
        if not high_priority:
            print("   âš  æ— é«˜ä¼˜å…ˆçº§ä»»åŠ¡ï¼Œè·³è¿‡æ‹†è§£")
            return {
                "recommended_task": None,
                "action_steps": [],
                "quick_start_action": None,
                "processing_steps": ["è¡ŒåŠ¨æ‹†è§£: æ— éœ€æ‹†è§£"]
            }
        
        # é€‰æ‹©ç¬¬ä¸€ä¸ªé«˜ä¼˜å…ˆçº§ä»»åŠ¡æ‹†è§£
        recommended_task = high_priority[0]
        
        # ä½¿ç”¨æ‹†è§£å·¥å…·
        decomposer = self.tools[4]  # ActionDecompositionTool
        
        result_json = decomposer._run(
            task=recommended_task["description"],
            total_minutes=recommended_task["estimated_minutes"],
            user_style="balanced"
        )
        
        result = json.loads(result_json)
        
        print(f"   âœ“ æ‹†è§£ä»»åŠ¡: {recommended_task['description'][:50]}")
        print(f"   âœ“ ç”Ÿæˆ {len(result['steps'])} ä¸ªæ­¥éª¤")
        print(f"   âœ“ å¿«é€Ÿå¯åŠ¨: {result['quick_start']['description']}")
        
        return {
            "recommended_task": recommended_task,
            "action_steps": result["steps"],
            "quick_start_action": result["quick_start"],
            "processing_steps": [f"è¡ŒåŠ¨æ‹†è§£: æ‹†æˆ {len(result['steps'])} æ­¥"]
        }
    
    def _personalization_node(self, state: AgentState) -> Dict[str, Any]:
        """èŠ‚ç‚¹6: ä¸ªæ€§åŒ–è°ƒæ•´"""
        print("ğŸ¯ [èŠ‚ç‚¹6] ä¸ªæ€§åŒ–è°ƒæ•´...")
        
        # è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡
        user_id = state.get("user_id", "default")
        
        # ä½¿ç”¨è®°å¿†æœç´¢å·¥å…·
        memory_tool = self.tools[3]  # MemorySearchTool
        
        try:
            memory_json = memory_tool._run(user_id=user_id, query="preferences")
            user_context = json.loads(memory_json)
        except:
            user_context = {}
        
        adjustments = []
        
        # åŸºäºè®°å¿†çš„è°ƒæ•´
        if user_context.get("morning_productivity"):
            adjustments.append("åŸºäºä½ çš„ä¹ æƒ¯ï¼Œé‡è¦ä»»åŠ¡å»ºè®®å®‰æ’åœ¨æ—©ä¸Šï¼ˆä½ æ—©ä¸Šæ•ˆç‡æœ€é«˜ï¼‰")
        
        if user_context.get("prefers_short_tasks"):
            adjustments.append("æˆ‘å·²ç»æŠŠä»»åŠ¡æ‹†æˆäº†å°å—ï¼ˆä½ åå¥½çŸ­æ—¶ä»»åŠ¡ï¼‰")
        
        if state.get("deferrable"):
            adjustments.append(f"å»ºè®®å»¶å {len(state['deferrable'])} ä¸ªä½ä¼˜å…ˆçº§ä»»åŠ¡ï¼Œä¸“æ³¨æ ¸å¿ƒå·¥ä½œ")
        
        print(f"   âœ“ ç”Ÿæˆ {len(adjustments)} æ¡ä¸ªæ€§åŒ–å»ºè®®")
        
        return {
            "user_context": user_context,
            "personalized_adjustments": adjustments,
            "processing_steps": [f"ä¸ªæ€§åŒ–: {len(adjustments)} æ¡è°ƒæ•´"]
        }
    
    def _output_generation_node(self, state: AgentState) -> Dict[str, Any]:
        """èŠ‚ç‚¹7: è¾“å‡ºç”Ÿæˆ"""
        print("âœ¨ [èŠ‚ç‚¹7] ç”Ÿæˆæœ€ç»ˆè¾“å‡º...")
        
        # æ„å»ºè¾“å‡º
        output_parts = []
        
        # 1. å¼€åœº + æ€»ç»“
        total_tasks = len(state.get("analyzed_tasks", []))
        output_parts.append(f"ğŸ“Š æˆ‘å¸®ä½ ç†äº†ä¸€ä¸‹ï¼Œä½ ä»Šå¤©çš„è´Ÿæ‹…æ¥è‡ª **{total_tasks} ç±»ä»»åŠ¡**ï¼š\n")
        
        # 2. é«˜ä¼˜å…ˆçº§
        high_priority = state.get("high_priority", [])
        if high_priority:
            output_parts.append("ğŸ“Œ **é«˜ä¼˜å…ˆçº§**ï¼ˆå¿…é¡»ä»Šå¤©å®Œæˆï¼‰")
            for i, task in enumerate(high_priority, 1):
                output_parts.append(f"  {i}. {task['description']} ({task['reason']})")
            output_parts.append("")
        
        # 3. ä¸­ä¼˜å…ˆçº§
        medium_priority = state.get("medium_priority", [])
        if medium_priority:
            output_parts.append("ğŸ“Œ **ä¸­ä¼˜å…ˆçº§**ï¼ˆä»Šå¤©å®Œæˆæ›´å¥½ï¼‰")
            for i, task in enumerate(medium_priority, 1):
                output_parts.append(f"  {i}. {task['description']}")
            output_parts.append("")
        
        # 4. å¯å»¶å
        deferrable = state.get("deferrable", [])
        if deferrable:
            output_parts.append("ğŸ“Œ **å¯å»¶å**ï¼ˆä¸å½±å“ä»Šå¤©æ ¸å¿ƒè¿›åº¦ï¼‰")
            for i, task_desc in enumerate(deferrable, 1):
                output_parts.append(f"  {i}. {task_desc}")
            output_parts.append("")
        
        # 5. ä¸‹ä¸€æ­¥è¡ŒåŠ¨
        quick_start = state.get("quick_start_action")
        if quick_start:
            output_parts.append("ğŸŸ¦ **ã€ä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‘**")
            output_parts.append(f"æˆ‘å»ºè®®ä»æœ€é‡è¦çš„ä»»åŠ¡å¼€å§‹ã€‚")
            output_parts.append(f"è¿™æ˜¯ä¸€ä¸ª **{quick_start['estimated_minutes']} åˆ†é’Ÿ**å°±èƒ½å¯åŠ¨çš„å°æ­¥éª¤ï¼š\n")
            output_parts.append(f"   â†’ {quick_start['description']}")
            output_parts.append(f"   ï¼ˆå®Œæˆç‡ï¼š0/1ï¼‰\n")
            output_parts.append("å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘å°†åœ¨ 15 åˆ†é’Ÿåæé†’ä½ å›æ¥ç»§ç»­ã€‚\n")
        
        # 6. ä¸ªæ€§åŒ–æç¤º
        adjustments = state.get("personalized_adjustments", [])
        if adjustments:
            output_parts.append("ğŸ’¡ **ä¸ªæ€§åŒ–è°ƒæ•´ï¼š**")
            for adj in adjustments:
                output_parts.append(f"  â€¢ {adj}")
            output_parts.append("")
        
        # 7. æ¿€åŠ±ç»“å°¾
        output_parts.append("â­ **æˆ‘å·²ç»å¸®ä½ æ•´ç†å¥½äº†ï¼š**\n")
        if high_priority:
            output_parts.append(f"â€¢ ä»Šå¤©ä½ åªè¦ä¸“æ³¨ **1 ä»¶æœ€é‡è¦çš„äº‹**ï¼ˆ{high_priority[0]['description'][:30]}...ï¼‰")
        if quick_start:
            output_parts.append(f"â€¢ ä»ä¸€ä¸ª **{quick_start['estimated_minutes']} åˆ†é’Ÿçš„å°æ­¥éª¤**å¼€å§‹å³å¯")
        if deferrable:
            output_parts.append(f"â€¢ æ¬¡è¦ä»»åŠ¡æˆ‘å·²æ›¿ä½ è‡ªåŠ¨å»¶åå®‰æ’")
        output_parts.append("â€¢ æˆ‘ä¼šé™ªä½ ä¸€èµ·æ¨è¿›ï¼Œ**ä¸ç”¨æ‹…å¿ƒå¤±æ§æ„Ÿ**ã€‚")
        
        final_message = "\n".join(output_parts)
        
        print(f"   âœ“ è¾“å‡ºç”Ÿæˆå®Œæˆ ({len(final_message)} å­—ç¬¦)")
        
        return {
            "final_message": final_message,
            "should_continue": False,
            "processing_steps": ["è¾“å‡ºç”Ÿæˆ: å®Œæˆæœ€ç»ˆæ¶ˆæ¯"]
        }
    
    def _emotion_support_node(self, state: AgentState) -> Dict[str, Any]:
        """æƒ…ç»ªæ”¯æŒèŠ‚ç‚¹"""
        print("ğŸ’š [æƒ…ç»ªæ”¯æŒ] ç”Ÿæˆæ¸©æš–å›åº”...")
        
        message = """å¬èµ·æ¥ä½ ç°åœ¨å‹åŠ›æŒºå¤§çš„ã€‚åˆ«æ€¥ï¼Œæˆ‘ä»¬ä¸€èµ·æ¥å¤„ç†ã€‚

è¦ä¸è¿™æ ·ï¼š
1ï¸âƒ£ å…ˆç”¨1åˆ†é’Ÿæ·±å‘¼å¸æ”¾æ¾ï¼Œç„¶åæˆ‘å¸®ä½ æŒ‘æœ€é‡è¦çš„
2ï¸âƒ£ ç›´æ¥è®©æˆ‘æŠŠä½ çš„äº‹æƒ…æ•´ç†æˆæ¸…å•

ä½ æƒ³è¯•è¯•å“ªä¸ªï¼Ÿ"""
        
        return {
            "final_message": message,
            "should_continue": False,
            "processing_steps": ["æƒ…ç»ªæ”¯æŒ: æä¾›æ¸©æš–å›åº”"]
        }
    
    def _route_by_intent(self, state: AgentState) -> str:
        """æ ¹æ®æ„å›¾è·¯ç”±"""
        intent = state.get("intent", "unknown")
        
        if intent in ["task", "decision"]:
            return "task"
        elif intent == "emotion":
            return "emotion"
        elif intent == "mixed":
            return "mixed"
        else:
            return "unknown"
    
    # =========================================================================
    # ä¸»æ‰§è¡Œå‡½æ•°
    # =========================================================================
    
    def run(self, user_id: str, user_input: str) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´å·¥ä½œæµ
        
        Args:
            user_id: ç”¨æˆ·ID
            user_input: ç”¨æˆ·è¾“å…¥
            
        Returns:
            åŒ…å«æœ€ç»ˆè¾“å‡ºå’Œæ‰€æœ‰ä¸­é—´çŠ¶æ€çš„å­—å…¸
        """
        print("\n" + "="*80)
        print(f"ğŸš€ LifeOS å·¥ä½œæµå¯åŠ¨")
        print(f"ç”¨æˆ·è¾“å…¥: {user_input[:100]}...")
        print("="*80 + "\n")
        
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state: AgentState = {
            "user_id": user_id,
            "user_input": user_input,
            "timestamp": datetime.now().isoformat(),
            "intent": "",
            "intent_confidence": 0.0,
            "raw_tasks": [],
            "analyzed_tasks": [],
            "high_priority": [],
            "medium_priority": [],
            "low_priority": [],
            "deferrable": [],
            "recommended_task": None,
            "action_steps": [],
            "quick_start_action": None,
            "user_context": None,
            "personalized_adjustments": [],
            "summary": "",
            "final_message": "",
            "next_action": "",
            "processing_steps": [],
            "errors": [],
            "should_continue": True,
            "needs_clarification": False,
        }
        
        # æ‰§è¡Œå·¥ä½œæµ
        final_state = self.app.invoke(initial_state)
        
        print("\n" + "="*80)
        print("âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ")
        print("="*80)
        
        # æ‰“å°å¤„ç†æ­¥éª¤
        print("\nğŸ“‹ å¤„ç†æ­¥éª¤ï¼š")
        for step in final_state.get("processing_steps", []):
            print(f"   â€¢ {step}")
        
        return final_state


# =============================================================================
# ä¾¿æ·å‡½æ•°
# =============================================================================

def create_workflow(
    llm_provider: str = None,
    db_path: str = "lifeos_data.db"
) -> LifeOSWorkflow:
    """åˆ›å»ºå·¥ä½œæµå®ä¾‹"""
    if llm_provider is None:
        llm_provider = os.getenv("LLM_PROVIDER", "mock")
    
    return LifeOSWorkflow(llm_provider, db_path)


__all__ = ['LifeOSWorkflow', 'create_workflow']
