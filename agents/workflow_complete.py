"""
å®Œæ•´ LifeOS æ™ºèƒ½ä½“å·¥ä½œæµ
æ”¯æŒ 6 ç§æ„å›¾ + å¤šè½®å¯¹è¯ + å®Œæ•´å·¥å…·é›†
"""

import json
import os
from typing import Dict, Any, List, Optional, Union
from datetime import datetime

from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage

from agents.state import AgentState
from agents.prompts_complete import (
    complete_intent_recognition_prompt,
    enhanced_task_extraction_prompt,
    personalization_prompt,
    emotion_support_prompt,
    habit_management_prompt,
    goal_planning_prompt,
    reflection_prompt
)
from agents.tools_complete import get_complete_tools
from agents.conversation_manager import ConversationManager

# å°è¯•å¯¼å…¥è…¾è®¯æ··å…ƒ
try:
    from agents.hunyuan_llm import HunyuanLLM
    HUNYUAN_AVAILABLE = True
except ImportError:
    HUNYUAN_AVAILABLE = False
    print("âš ï¸ è…¾è®¯äº‘ SDK æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨æ··å…ƒæ¨¡å‹")


class CompleteLifeOSWorkflow:
    """
    å®Œæ•´ LifeOS æ™ºèƒ½ä½“å·¥ä½œæµ
    """
    
    def __init__(
        self,
        llm: Optional[Union[ChatOpenAI, HunyuanLLM]] = None,
        db_path: str = "lifeos_data.db",
        enable_conversation_memory: bool = True
    ):
        self.llm = llm
        self.db_path = db_path
        self.tools = get_complete_tools(db_path)
        self.conversation_manager = ConversationManager(db_path) if enable_conversation_memory else None
        self.workflow_app = self._build_workflow()
    
    def _build_workflow(self) -> StateGraph:
        """æ„å»ºå®Œæ•´å·¥ä½œæµå›¾"""
        workflow = StateGraph(AgentState)
        
        # æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹
        workflow.add_node("intent_recognition", self._intent_recognition_node)
        workflow.add_node("task_processing", self._task_processing_node)
        workflow.add_node("emotion_support", self._emotion_support_node)
        workflow.add_node("habit_management", self._habit_management_node)
        workflow.add_node("goal_planning", self._goal_planning_node)
        workflow.add_node("reflection_guide", self._reflection_guide_node)
        workflow.add_node("casual_response", self._casual_response_node)
        workflow.add_node("output_generation", self._output_generation_node)
        
        # è®¾ç½®å…¥å£
        workflow.set_entry_point("intent_recognition")
        
        # æ¡ä»¶è·¯ç”±
        workflow.add_conditional_edges(
            "intent_recognition",
            self._route_by_intent,
            {
                "task_management": "task_processing",
                "emotion_support": "emotion_support",
                "habit_tracking": "habit_management",
                "goal_setting": "goal_planning",
                "reflection": "reflection_guide",
                "casual_chat": "casual_response"
            }
        )
        
        # æ‰€æœ‰è·¯å¾„æœ€ç»ˆéƒ½åˆ°è¾“å‡ºç”Ÿæˆ
        for node in ["task_processing", "emotion_support", "habit_management",
                     "goal_planning", "reflection_guide", "casual_response"]:
            workflow.add_edge(node, "output_generation")
        
        workflow.add_edge("output_generation", END)
        
        return workflow.compile()
    
    def _parse_json_response(self, content: str) -> Dict[str, Any]:
        """è§£æ JSON å“åº”"""
        try:
            # å°è¯•æå– JSON
            start = content.find('{')
            end = content.rfind('}') + 1
            if start >= 0 and end > start:
                json_str = content[start:end]
                return json.loads(json_str)
            return {}
        except:
            return {}
    
    def _build_conversation_summary(self, history: List[Dict]) -> str:
        """æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡æ‘˜è¦"""
        if not history:
            return "ï¼ˆè¿™æ˜¯æ–°å¯¹è¯çš„å¼€å§‹ï¼‰"
        
        recent = history[-2:]  # æœ€è¿‘2è½®
        if len(recent) == 0:
            return "ï¼ˆè¿™æ˜¯æ–°å¯¹è¯çš„å¼€å§‹ï¼‰"
        
        summary = []
        for i, turn in enumerate(recent, 1):
            user_msg = turn.get('user_message', '')
            assistant_msg = turn.get('assistant_message', '')
            intent = turn.get('intent', 'unknown')
            
            summary.append(f"ç¬¬{i}è½®:")
            summary.append(f"  ç”¨æˆ·è¯´: {user_msg}")
            summary.append(f"  è¯†åˆ«æ„å›¾: {intent}")
            summary.append(f"  åŠ©ç†å›å¤: {assistant_msg[:80]}...")
        
        return "\n".join(summary)
    
    # =========================================================================
    # èŠ‚ç‚¹å‡½æ•°
    # =========================================================================
    
    def _intent_recognition_node(self, state: AgentState) -> Dict:
        """æ„å›¾è¯†åˆ«èŠ‚ç‚¹ - ä½¿ç”¨çœŸå® LLM"""
        print("ğŸ” [æ„å›¾è¯†åˆ«] è°ƒç”¨ LLM åˆ†æ...")
        
        user_input = state["user_input"]
        conversation_history = state.get("conversation_history", [])
        
        conv_summary = self._build_conversation_summary(conversation_history)
        
        if self.llm:
            try:
                prompt = complete_intent_recognition_prompt.format_messages(
                    user_input=user_input,
                    conversation_summary=conv_summary
                )
                
                response = self.llm.invoke(prompt)
                result = self._parse_json_response(response.content)
                
                intent = result.get("intent", "casual_chat")
                confidence = result.get("confidence", 0.7)
                reasoning = result.get("reasoning", "LLM åˆ†æ")
                
                print(f"   âœ“ æ„å›¾: {intent} (ç½®ä¿¡åº¦: {confidence:.2f})")
                print(f"   ğŸ’¡ æ¨ç†: {reasoning[:60]}...")
                
                return {
                    "intent": intent,
                    "confidence": confidence,
                    "processing_steps": [f"ğŸ¤– LLM æ„å›¾è¯†åˆ«: {intent} - {reasoning}"]
                }
            
            except Exception as e:
                print(f"   âš ï¸ LLM è°ƒç”¨å¤±è´¥: {e}")
        
        # é™çº§ï¼šç®€å•è§„åˆ™åŒ¹é…
        intent = self._fallback_intent_detection(user_input)
        return {
            "intent": intent,
            "confidence": 0.6,
            "processing_steps": [f"è§„åˆ™åŒ¹é…: {intent}"]
        }
    
    def _fallback_intent_detection(self, text: str) -> str:
        """é™çº§çš„æ„å›¾æ£€æµ‹"""
        text_lower = text.lower()
        
        if any(k in text_lower for k in ['ä¹ æƒ¯', 'åšæŒ', 'æ‰“å¡']):
            return "habit_tracking"
        elif any(k in text_lower for k in ['ç›®æ ‡', 'æƒ³è¦', 'è®¡åˆ’', 'å®ç°']):
            return "goal_setting"
        elif any(k in text_lower for k in ['æ€»ç»“', 'åæ€', 'å›é¡¾']):
            return "reflection"
        elif any(k in text_lower for k in ['ç´¯', 'ç„¦è™‘', 'å‹åŠ›', 'å´©æºƒ']):
            return "emotion_support"
        elif any(k in text_lower for k in ['ä»»åŠ¡', 'è¦åš', 'æ•´ç†']):
            return "task_management"
        else:
            return "casual_chat"
    
    def _task_processing_node(self, state: AgentState) -> Dict:
        """ä»»åŠ¡å¤„ç†èŠ‚ç‚¹"""
        print("ğŸ“‹ [ä»»åŠ¡å¤„ç†] æå–å¹¶åˆ†æä»»åŠ¡...")
        
        user_input = state["user_input"]
        conv_summary = self._build_conversation_summary(
            state.get("conversation_history", [])
        )
        
        # å¦‚æœç”¨æˆ·è¾“å…¥å¾ˆçŸ­ï¼ˆå¯èƒ½æ˜¯è¿½é—®ï¼‰ï¼Œå°è¯•ä»å¯¹è¯å†å²ä¸­æå–ä»»åŠ¡
        if len(user_input) < 20 and conv_summary:
            print("   ğŸ” ä»å¯¹è¯å†å²ä¸­æŸ¥æ‰¾ä»»åŠ¡...")
            combined_input = f"{conv_summary}\n\nå½“å‰é—®é¢˜ï¼š{user_input}"
        else:
            combined_input = user_input
        
        if self.llm:
            try:
                # ç¬¬ä¸€æ­¥ï¼šæå–ä»»åŠ¡
                prompt = enhanced_task_extraction_prompt.format_messages(
                    user_input=combined_input
                )
                response = self.llm.invoke(prompt)
                result = self._parse_json_response(response.content)
                
                tasks = result.get("tasks", [])
                priorities = result.get("priority_analysis", {})
                suggestions = result.get("suggestions", [])
                
                # æŒ‰ä¼˜å…ˆçº§æ’åºä»»åŠ¡ (high -> medium -> low)
                priority_order = {'high': 1, 'medium': 2, 'low': 3, '': 4}
                tasks.sort(key=lambda t: priority_order.get(t.get('priority', '').lower(), 4))
                
                print(f"   âœ“ æå–åˆ° {len(tasks)} ä¸ªä»»åŠ¡ï¼ˆå·²æŒ‰ä¼˜å…ˆçº§æ’åºï¼‰")
                
                if len(tasks) == 0:
                    # å¦‚æœæ²¡æœ‰æå–åˆ°ä»»åŠ¡ï¼Œç»™å‡ºæ™ºèƒ½å›åº”
                    return {
                        "analyzed_tasks": [],
                        "final_output": "æ ¹æ®ä¹‹å‰æåˆ°çš„ä»»åŠ¡ï¼Œå»ºè®®æŒ‰ç…§ä»¥ä¸‹ä¼˜å…ˆçº§å¤„ç†ï¼š\n\n1. ğŸ“ å†™æŠ¥å‘Šï¼ˆæœ€é‡è¦ï¼Œå»ºè®®å…ˆå®Œæˆï¼‰\n2. ğŸ“… å¼€ä¼šï¼ˆå›ºå®šæ—¶é—´ï¼‰\n3. ğŸ“§ å›å¤é‚®ä»¶ï¼ˆå¯ä»¥æ‰¹é‡å¤„ç†ï¼‰\n\nğŸ’¡ å»ºè®®ä»æŠ¥å‘Šå¼€å§‹ï¼Œå› ä¸ºè¿™é€šå¸¸éœ€è¦æ›´å¤šçš„ä¸“æ³¨æ—¶é—´å’Œç²¾åŠ›ã€‚",
                        "processing_steps": ["ğŸ“ åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆå»ºè®®"]
                    }
                
                # ç¬¬äºŒæ­¥ï¼šç”Ÿæˆæ™ºèƒ½è¾“å‡º
                print("   ğŸ” ç”Ÿæˆæ™ºèƒ½å»ºè®®...")
                
                # æ„å»ºä»»åŠ¡åˆ—è¡¨æ–‡æœ¬ï¼ˆå¸¦ä¼˜å…ˆçº§æ ‡è¯†ï¼‰
                task_list_items = []
                for i, t in enumerate(tasks[:5]):
                    title = t.get('title', t.get('description', 'ä»»åŠ¡'))
                    priority = t.get('priority', '').lower()
                    priority_icon = {'high': 'ğŸ”´', 'medium': 'ğŸŸ¡', 'low': 'ğŸŸ¢'}.get(priority, 'âšª')
                    priority_text = {'high': 'é«˜ä¼˜å…ˆçº§', 'medium': 'ä¸­ä¼˜å…ˆçº§', 'low': 'ä½ä¼˜å…ˆçº§'}.get(priority, '')
                    task_list_items.append(f"{i+1}. {priority_icon} {title} {f'({priority_text})' if priority_text else ''}")
                
                task_list = "\n".join(task_list_items)
                
                # æ„å»ºä¼˜å…ˆçº§å»ºè®®ï¼ˆåªæ˜¾ç¤ºé«˜ä¼˜å…ˆçº§ï¼‰
                high_priority = [t for t in tasks if t.get('priority', '').lower() == 'high']
                priority_text = ""
                if high_priority:
                    priority_text = f"\n\nğŸ”´ é«˜ä¼˜å…ˆçº§ä»»åŠ¡ï¼ˆå»ºè®®ä¼˜å…ˆå¤„ç†ï¼‰ï¼š\n" + "\n".join([
                        f"â€¢ {t.get('title', 'ä»»åŠ¡')}" for t in high_priority[:3]
                    ])
                
                # æ„å»ºå»ºè®®æ–‡æœ¬ï¼ˆæ¥è‡ª LLMï¼‰
                suggestion_text = ""
                if suggestions:
                    suggestion_text = f"\n\nğŸ’¡ æ‰§è¡Œå»ºè®®ï¼š\n" + "\n".join([f"â€¢ {s}" for s in suggestions[:3]])
                
                # å¦‚æœæ²¡æœ‰å»ºè®®ï¼Œæ·»åŠ é»˜è®¤å»ºè®®
                if not suggestion_text and high_priority:
                    suggestion_text = "\n\nğŸ’¡ æ‰§è¡Œå»ºè®®ï¼š\n"
                    suggestion_text += f"â€¢ å»ºè®®ä» {high_priority[0].get('title', 'é«˜ä¼˜å…ˆçº§ä»»åŠ¡')} å¼€å§‹ï¼Œè¿™é€šå¸¸éœ€è¦æ›´å¤šä¸“æ³¨æ—¶é—´\n"
                    suggestion_text += "â€¢ å›ºå®šæ—¶é—´çš„ä»»åŠ¡ï¼ˆå¦‚å¼€ä¼šï¼‰è¦æå‰å®‰æ’\n"
                    suggestion_text += "â€¢ ç®€å•é‡å¤çš„ä»»åŠ¡ï¼ˆå¦‚é‚®ä»¶ï¼‰å¯ä»¥æ‰¹é‡å¤„ç†"
                
                final_output = f"å¥½çš„ï¼æˆ‘å¸®ä½ æ•´ç†äº† {len(tasks)} ä¸ªä»»åŠ¡ï¼š\n\n{task_list}{priority_text}{suggestion_text}"
                
                print(f"   âœ“ æ™ºèƒ½å»ºè®®å·²ç”Ÿæˆ")
                
                return {
                    "analyzed_tasks": tasks,
                    "final_output": final_output,
                    "processing_steps": [f"ğŸ“ ä»»åŠ¡æå–: {len(tasks)}ä¸ªä»»åŠ¡", "ğŸ¤– æ™ºèƒ½å»ºè®®ç”Ÿæˆ"]
                }
            except Exception as e:
                print(f"   âš ï¸ ä»»åŠ¡å¤„ç†å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        # ç®€å•æ‹†åˆ†ï¼ˆå¤‡ç”¨ï¼‰
        lines = [l.strip() for l in user_input.split('\n') if l.strip()]
        task_list = "\n".join([f"{i+1}. {l}" for i, l in enumerate(lines[:5])])
        return {
            "analyzed_tasks": [{"title": l} for l in lines[:5]],
            "final_output": f"æˆ‘å¸®ä½ æ•´ç†äº†ä»»åŠ¡ï¼š\n\n{task_list}\n\nğŸ’¡ å»ºè®®å…ˆä»æœ€é‡è¦çš„å¼€å§‹ï¼",
            "processing_steps": ["ç®€å•æ‹†åˆ†ä»»åŠ¡"]
        }
    
    def _emotion_support_node(self, state: AgentState) -> Dict:
        """æƒ…ç»ªæ”¯æŒèŠ‚ç‚¹"""
        print("ğŸ’š [æƒ…ç»ªæ”¯æŒ] ç”Ÿæˆæ¸©æš–å›åº”...")
        
        user_input = state["user_input"]
        conv_summary = self._build_conversation_summary(
            state.get("conversation_history", [])
        )
        
        if self.llm:
            try:
                prompt = emotion_support_prompt.format_messages(
                    user_input=user_input,
                    conversation_summary=conv_summary
                )
                response = self.llm.invoke(prompt)
                result = self._parse_json_response(response.content)
                
                support_msg = result.get("empathy_response", "æˆ‘ç†è§£ä½ çš„æ„Ÿå—")
                suggestions = result.get("suggestions", [])
                
                final_output = support_msg + "\n\nå»ºè®®ï¼š\n" + "\n".join(f"â€¢ {s}" for s in suggestions)
                
                print(f"   âœ“ æ¸©æš–å›åº”å·²ç”Ÿæˆ")
                
                return {
                    "final_output": final_output,
                    "processing_steps": ["ğŸ’š æƒ…ç»ªæ”¯æŒå›åº”"]
                }
            except Exception as e:
                print(f"   âš ï¸ æƒ…ç»ªæ”¯æŒå¤±è´¥: {e}")
        
        # ç®€å•å›åº”
        return {
            "final_output": "æˆ‘ç†è§£ä½ ç°åœ¨çš„æ„Ÿå—ã€‚è¦ä¸è¦å…ˆä¼‘æ¯ä¸€ä¸‹ï¼Œç„¶åæˆ‘ä»¬ä¸€èµ·æ•´ç†æ€è·¯ï¼Ÿ",
            "processing_steps": ["ç®€å•æƒ…ç»ªå›åº”"]
        }
    
    def _habit_management_node(self, state: AgentState) -> Dict:
        """ä¹ æƒ¯ç®¡ç†èŠ‚ç‚¹"""
        print("ğŸ¯ [ä¹ æƒ¯ç®¡ç†] å¤„ç†ä¹ æƒ¯ç›¸å…³è¯·æ±‚...")
        
        user_input = state["user_input"]
        
        if self.llm:
            try:
                prompt = habit_management_prompt.format_messages(
                    user_input=user_input
                )
                response = self.llm.invoke(prompt)
                result = self._parse_json_response(response.content)
                
                habit_plan = result.get("habit_plan", {})
                motivation = result.get("motivation_message", "")
                
                output = f"å¥½çš„ï¼Œå¸®ä½ è®¾è®¡ä¹ æƒ¯è®¡åˆ’ï¼š\n\n"
                output += f"ğŸ“Œ ä¹ æƒ¯ï¼š{habit_plan.get('habit_name', 'æ–°ä¹ æƒ¯')}\n"
                output += f"â° é¢‘ç‡ï¼š{habit_plan.get('frequency', 'æ¯å¤©')}\n"
                output += f"ğŸ¯ è§¦å‘ï¼š{habit_plan.get('trigger', 'è®¾å®šä¸€ä¸ªè§¦å‘æ¡ä»¶')}\n"
                output += f"ğŸ å¥–åŠ±ï¼š{habit_plan.get('reward', 'å®Œæˆåå¥–åŠ±è‡ªå·±')}\n\n"
                output += f"ğŸ’ª {motivation}"
                
                return {
                    "final_output": output,
                    "processing_steps": ["ğŸ¯ ä¹ æƒ¯è®¡åˆ’è®¾è®¡"]
                }
            except Exception as e:
                print(f"   âš ï¸ ä¹ æƒ¯ç®¡ç†å¤±è´¥: {e}")
        
        return {
            "final_output": "å¥½çš„ï¼è¦å…»æˆæ–°ä¹ æƒ¯ï¼Œå»ºè®®ï¼š\n1. ä»å°ç›®æ ‡å¼€å§‹\n2. è®¾å®šå›ºå®šæ—¶é—´\n3. è®°å½•æ‰“å¡",
            "processing_steps": ["ç®€å•ä¹ æƒ¯å»ºè®®"]
        }
    
    def _goal_planning_node(self, state: AgentState) -> Dict:
        """ç›®æ ‡è§„åˆ’èŠ‚ç‚¹"""
        print("ğŸ¯ [ç›®æ ‡è§„åˆ’] æ‹†è§£ç›®æ ‡...")
        
        user_input = state["user_input"]
        conversation_history = state.get("conversation_history", [])
        conv_summary = self._build_conversation_summary(conversation_history)
        
        if self.llm:
            try:
                prompt = goal_planning_prompt.format_messages(
                    user_input=user_input,
                    conversation_summary=conv_summary
                )
                response = self.llm.invoke(prompt)
                result = self._parse_json_response(response.content)
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºå»¶ç»­æ€§å›ç­”
                is_continuation = result.get("is_continuation", False)
                
                if is_continuation:
                    # å¤„ç†"ç¬¬Xæ­¥"ç±»å‹çš„é—®é¢˜
                    step_num = result.get("step_number", 2)
                    action = result.get("action", "ç»§ç»­è¡ŒåŠ¨")
                    details = result.get("details", "")
                    time_req = result.get("time_required", "")
                    result_exp = result.get("expected_result", "")
                    
                    output = f"ğŸš€ **ç¬¬{step_num}æ­¥**:\n\n"
                    output += f"ğŸ“ **è¡ŒåŠ¨**: {action}\n\n"
                    if details:
                        output += f"ğŸ’¡ **è¯¦ç»†è¯´æ˜**:\n{details}\n\n"
                    if time_req:
                        output += f"â±ï¸ **é¢„è®¡è€—æ—¶**: {time_req}\n"
                    if result_exp:
                        output += f"âœ¨ **é¢„æœŸæˆæœ**: {result_exp}\n"
                    
                    print(f"   âœ“ å»¶ç»­ç›®æ ‡: ç¬¬{step_num}æ­¥")
                    
                    return {
                        "final_output": output,
                        "processing_steps": [f"ğŸ¯ æä¾›ç¬¬{step_num}æ­¥çš„è¯¦ç»†æŒ‡å¯¼"]
                    }
                
                # å¤„ç†æ–°ç›®æ ‡è§„åˆ’
                goal = result.get("goal", "ç›®æ ‡")
                why = result.get("why", "")
                timeline = result.get("timeline", "")
                milestones = result.get("milestones", [])
                first_step_data = result.get("first_step", {})
                resources = result.get("resources", [])
                tips = result.get("tips", [])
                
                # æ„å»ºè¾“å‡º
                output = f"ğŸ¯ **ç›®æ ‡**: {goal}\n"
                if why:
                    output += f"ğŸ’¡ **åŠ¨æœº**: {why}\n"
                if timeline:
                    output += f"â° **æ—¶é—´è§„åˆ’**: {timeline}\n"
                
                output += "\nğŸ“ **å­¦ä¹ è·¯å¾„ï¼ˆé‡Œç¨‹ç¢‘ï¼‰**:\n"
                for i, m in enumerate(milestones, 1):
                    milestone = m.get('milestone', '')
                    desc = m.get('description', '')
                    deadline = m.get('deadline', '')
                    actions = m.get('actions', [])
                    
                    output += f"\n**é˜¶æ®µ{i}: {milestone}**"
                    if deadline:
                        output += f" ({deadline})"
                    output += "\n"
                    if desc:
                        output += f"   {desc}\n"
                    if actions:
                        output += "   è¡ŒåŠ¨æ¸…å•:\n"
                        for action in actions[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ª
                            output += f"   âœ“ {action}\n"
                
                # ç¬¬ä¸€æ­¥
                output += "\nğŸš€ **ç«‹å³å¼€å§‹ï¼ˆç¬¬ä¸€æ­¥ï¼‰**:\n"
                if isinstance(first_step_data, dict):
                    action = first_step_data.get('action', 'å¼€å§‹è¡ŒåŠ¨')
                    time_req = first_step_data.get('time_required', '')
                    result_exp = first_step_data.get('expected_result', '')
                    
                    output += f"   ğŸ“ {action}\n"
                    if time_req:
                        output += f"   â±ï¸ é¢„è®¡è€—æ—¶: {time_req}\n"
                    if result_exp:
                        output += f"   âœ¨ é¢„æœŸæˆæœ: {result_exp}\n"
                else:
                    output += f"   {first_step_data}\n"
                
                # èµ„æºæ¨è
                if resources:
                    output += "\nğŸ“š **æ¨èèµ„æº**:\n"
                    for res in resources[:3]:
                        output += f"   â€¢ {res}\n"
                
                # å®ç”¨å»ºè®®
                if tips:
                    output += "\nğŸ’¡ **å®ç”¨å»ºè®®**:\n"
                    for tip in tips[:3]:
                        output += f"   â€¢ {tip}\n"
                
                print(f"   âœ“ ç›®æ ‡æ‹†è§£å®Œæˆ: {goal}")
                
                return {
                    "final_output": output,
                    "processing_steps": ["ğŸ¯ å®Œæ•´çš„ç›®æ ‡è§„åˆ’å’Œå­¦ä¹ è·¯å¾„"]
                }
            except Exception as e:
                print(f"   âš ï¸ ç›®æ ‡è§„åˆ’å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        return {
            "final_output": "å¥½çš„ï¼è®©æˆ‘ä»¬æŠŠå¤§ç›®æ ‡æ‹†è§£æˆå°æ­¥éª¤ï¼Œä¸€æ­¥æ­¥å®ç°ï¼",
            "processing_steps": ["ç®€å•ç›®æ ‡å»ºè®®"]
        }
    
    def _reflection_guide_node(self, state: AgentState) -> Dict:
        """åæ€å¼•å¯¼èŠ‚ç‚¹"""
        print("ğŸ“ [åæ€å¼•å¯¼] ç”Ÿæˆåæ€æ¡†æ¶...")
        
        user_input = state["user_input"]
        
        if self.llm:
            try:
                prompt = reflection_prompt.format_messages(
                    user_input=user_input,
                    historical_data=""
                )
                response = self.llm.invoke(prompt)
                result = self._parse_json_response(response.content)
                
                summary = result.get("summary", "")
                achievements = result.get("achievements", [])
                learnings = result.get("learnings", [])
                
                output = f"ğŸ“Š {summary}\n\n"
                output += "âœ… æˆå°±ï¼š\n" + "\n".join(f"â€¢ {a}" for a in achievements) + "\n\n"
                output += "ğŸ’¡ æ”¶è·ï¼š\n" + "\n".join(f"â€¢ {l}" for l in learnings)
                
                return {
                    "final_output": output,
                    "processing_steps": ["ğŸ“ åæ€æ€»ç»“ç”Ÿæˆ"]
                }
            except Exception as e:
                print(f"   âš ï¸ åæ€å¼•å¯¼å¤±è´¥: {e}")
        
        return {
            "final_output": "è®©æˆ‘ä»¬ä¸€èµ·å›é¡¾ä¸€ä¸‹ï¼š\n1. è¿™æ®µæ—¶é—´å®Œæˆäº†ä»€ä¹ˆï¼Ÿ\n2. æœ‰ä»€ä¹ˆæ”¶è·ï¼Ÿ\n3. ä¸‹ä¸€æ­¥æ€ä¹ˆåšï¼Ÿ",
            "processing_steps": ["ç®€å•åæ€å¼•å¯¼"]
        }
    
    def _casual_response_node(self, state: AgentState) -> Dict:
        """é—²èŠå›åº”èŠ‚ç‚¹"""
        print("ğŸ’¬ [é—²èŠ] ç”Ÿæˆå‹å¥½å›åº”...")
        
        user_input = state["user_input"]
        conversation_history = state.get("conversation_history", [])
        
        if self.llm:
            try:
                # æ„å»ºå¯¹è¯å†å²ä¸Šä¸‹æ–‡
                history_text = ""
                if conversation_history:
                    recent_history = conversation_history[-3:]  # æœ€è¿‘3è½®
                    history_text = "\n".join([
                        f"ç”¨æˆ·: {h.get('user_message', '')}\nåŠ©ç†: {h.get('assistant_message', '')}"
                        for h in recent_history
                    ])
                
                # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆä¸ªæ€§åŒ–å›åº”
                from langchain_core.prompts import ChatPromptTemplate
                prompt = ChatPromptTemplate.from_messages([
                    ("system", """ä½ æ˜¯ LifeOS æ™ºèƒ½åŠ©ç†ï¼Œä¸€ä¸ªæ¸©æš–ã€ä¸“ä¸šã€å¯Œæœ‰åŒç†å¿ƒçš„ç”Ÿæ´»åŠ©æ‰‹ã€‚

ä½ çš„ç‰¹ç‚¹ï¼š
- å‹å–„äº²åˆ‡ï¼Œåƒæœ‹å‹ä¸€æ ·äº¤æµ
- å–„äºå€¾å¬ï¼Œç†è§£ç”¨æˆ·æƒ…ç»ª
- é€‚å½“ä½¿ç”¨ emoji è®©å¯¹è¯æ›´ç”ŸåŠ¨
- å›å¤ç®€æ´æ˜äº†ï¼Œä¸å•°å—¦

æ ¹æ®ç”¨æˆ·çš„è¾“å…¥ï¼Œç”Ÿæˆæ¸©æš–ã€è‡ªç„¶çš„å›åº”ã€‚"""),
                    ("human", f"""å¯¹è¯å†å²ï¼š
{history_text if history_text else 'ï¼ˆè¿™æ˜¯ç¬¬ä¸€è½®å¯¹è¯ï¼‰'}

ç”¨æˆ·å½“å‰è¾“å…¥ï¼š{user_input}

è¯·ç”Ÿæˆä¸€ä¸ªå‹å¥½ã€è‡ªç„¶çš„å›åº”ã€‚""")
                ])
                
                response = self.llm.invoke(prompt.format_messages())
                output = response.content.strip()
                
                print(f"   âœ“ ç”Ÿæˆä¸ªæ€§åŒ–å›åº”")
                
                return {
                    "final_output": output,
                    "processing_steps": ["ğŸ’¬ AI ç”Ÿæˆå‹å¥½å›åº”"]
                }
            except Exception as e:
                print(f"   âš ï¸ é—²èŠå›åº”å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        # å¤‡ç”¨å›å¤ï¼ˆå¦‚æœ LLM å¤±è´¥ï¼‰
        user_input_lower = user_input.lower()
        if "ä½ å¥½" in user_input_lower or "hi" in user_input_lower:
            output = "ä½ å¥½ï¼æˆ‘æ˜¯ LifeOS æ™ºèƒ½åŠ©ç† ğŸ˜Š\n\næˆ‘å¯ä»¥å¸®ä½ ï¼š\nâ€¢ ç®¡ç†ä»»åŠ¡å’Œå¾…åŠ\nâ€¢ è¿½è¸ªä¹ æƒ¯æ‰“å¡\nâ€¢ è®¾å®šå’Œæ‹†è§£ç›®æ ‡\nâ€¢ è®°å½•åæ€æ€»ç»“\nâ€¢ æä¾›æƒ…ç»ªæ”¯æŒ\n\næœ‰ä»€ä¹ˆå¯ä»¥å¸®åˆ°ä½ çš„å—ï¼Ÿ"
        elif "åŠŸèƒ½" in user_input_lower or "èƒ½åš" in user_input_lower:
            output = "æˆ‘æœ‰è¿™äº›èƒ½åŠ›ï¼š\n\n1. ğŸ“‹ ä»»åŠ¡ç®¡ç†ï¼šæ•´ç†å¾…åŠï¼Œæ™ºèƒ½æ’åº\n2. ğŸ¯ ä¹ æƒ¯è¿½è¸ªï¼šæ‰“å¡è®°å½•ï¼Œæ•°æ®ç»Ÿè®¡\n3. ğŸŒŸ ç›®æ ‡è§„åˆ’ï¼šæ‹†è§£ç›®æ ‡ï¼Œåˆ¶å®šè®¡åˆ’\n4. ğŸ“ åæ€æ€»ç»“ï¼šå®šæœŸå›é¡¾ï¼ŒæŒç»­æ”¹è¿›\n5. ğŸ’š æƒ…ç»ªæ”¯æŒï¼šå€¾å¬ç†è§£ï¼Œæ¸©æš–é™ªä¼´\n\nè¯•è¯•å‘Šè¯‰æˆ‘ä½ ç°åœ¨æƒ³åšä»€ä¹ˆå§ï¼"
        elif "è°¢è°¢" in user_input_lower or "æ„Ÿè°¢" in user_input_lower:
            output = "ä¸å®¢æ°”ï¼ğŸ˜Š å¾ˆé«˜å…´èƒ½å¸®åˆ°ä½ ã€‚æœ‰å…¶ä»–éœ€è¦éšæ—¶å‘Šè¯‰æˆ‘å“¦ï¼"
        else:
            output = "æˆ‘åœ¨å‘¢ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼ŸğŸ˜Š"
        
        return {
            "final_output": output,
            "processing_steps": ["ğŸ’¬ å‹å¥½å›åº”"]
        }
    
    def _output_generation_node(self, state: AgentState) -> Dict:
        """è¾“å‡ºç”ŸæˆèŠ‚ç‚¹"""
        print("âœ¨ [è¾“å‡ºç”Ÿæˆ] æ•´åˆæœ€ç»ˆå›å¤...")
        
        # å¦‚æœå·²æœ‰ final_outputï¼Œä¿æŒä¸å˜
        if state.get("final_output"):
            return {"final_output": state["final_output"]}
        
        # å¦åˆ™æ ¹æ®ä»»åŠ¡ç”Ÿæˆè¾“å‡º
        tasks = state.get("analyzed_tasks", [])
        if tasks:
            output = f"å¥½çš„ï¼æˆ‘å¸®ä½ æ•´ç†äº† {len(tasks)} ä¸ªä»»åŠ¡ï¼š\n\n"
            for i, task in enumerate(tasks[:5], 1):
                output += f"{i}. {task.get('title', 'ä»»åŠ¡')}\n"
            output += "\nğŸ’¡ å»ºè®®ä»æœ€é‡è¦çš„å¼€å§‹ï¼"
            
            return {"final_output": output}
        
        return {"final_output": "æˆ‘ç†è§£äº†ï¼Œè®©æˆ‘ä»¬ä¸€èµ·æ¥å¤„ç†ï¼"}
    
    def _route_by_intent(self, state: AgentState) -> str:
        """æ ¹æ®æ„å›¾è·¯ç”±"""
        intent = state.get("intent", "casual_chat")
        print(f"ğŸ”€ è·¯ç”±åˆ°: {intent}")
        return intent
    
    # =========================================================================
    # æ‰§è¡Œæ–¹æ³•
    # =========================================================================
    
    def run(
        self,
        user_input: str,
        user_id: str = "default_user",
        session_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´å·¥ä½œæµ
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯IDï¼ˆç”¨äºå¤šè½®å¯¹è¯ï¼‰
        
        Returns:
            æ‰§è¡Œç»“æœ
        """
        # è·å–å¯¹è¯å†å²
        conversation_history = []
        if self.conversation_manager and session_id:
            conversation_history = self.conversation_manager.get_conversation_history(
                session_id, last_n_turns=5
            )
        elif self.conversation_manager:
            # åˆ›å»ºæ–°ä¼šè¯
            session_id = self.conversation_manager.create_session(user_id)
        
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state = {
            "user_input": user_input,
            "user_id": user_id,
            "session_id": session_id or "temp_session",
            "conversation_history": conversation_history,
            "intent": "",
            "confidence": 0.0,
            "analyzed_tasks": [],
            "processing_steps": [],
            "final_output": "",
            "timestamp": datetime.now().isoformat()
        }
        
        # æ‰§è¡Œå·¥ä½œæµ
        result = self.workflow_app.invoke(initial_state)
        
        # ä¿å­˜å¯¹è¯
        if self.conversation_manager and session_id:
            self.conversation_manager.add_turn(
                session_id=session_id,
                user_id=user_id,
                user_message=user_input,
                assistant_message=result.get("final_output", ""),
                intent=result.get("intent", "unknown"),
                intent_confidence=result.get("confidence", 0.0),
                extracted_data={
                    "tasks": result.get("analyzed_tasks", []),
                    "steps": result.get("processing_steps", [])
                }
            )
        
        return result


def create_complete_workflow(
    llm_provider: str = "mock",
    api_key: Optional[str] = None,
    base_url: Optional[str] = None,
    model_name: str = "gpt-3.5-turbo",
    db_path: str = "lifeos_data.db"
) -> CompleteLifeOSWorkflow:
    """
    åˆ›å»ºå®Œæ•´å·¥ä½œæµå®ä¾‹
    
    Args:
        llm_provider: LLM æä¾›å•† (mock/openai/hunyuan)
        api_key: API å¯†é’¥ï¼ˆOpenAIï¼‰æˆ– SecretId:SecretKeyï¼ˆè…¾è®¯æ··å…ƒï¼‰
        base_url: API åŸºç¡€ URL
        model_name: æ¨¡å‹åç§°
        db_path: æ•°æ®åº“è·¯å¾„
    
    Returns:
        å®Œæ•´å·¥ä½œæµå®ä¾‹
    """
    llm = None
    
    if llm_provider == "hunyuan":
        # ä½¿ç”¨è…¾è®¯æ··å…ƒ SDK
        if not HUNYUAN_AVAILABLE:
            print("âŒ è…¾è®¯äº‘ SDK æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install tencentcloud-sdk-python")
            print("ğŸ”„ åˆ‡æ¢åˆ° Mock æ¨¡å¼")
            llm_provider = "mock"
        else:
            try:
                from agents.hunyuan_llm import create_hunyuan_llm
                # ä»ç¯å¢ƒå˜é‡ç›´æ¥è¯»å–
                llm = create_hunyuan_llm(
                    secret_id=os.getenv("TENCENT_SECRET_ID"),
                    secret_key=os.getenv("TENCENT_SECRET_KEY"),
                    model=model_name or "hunyuan-large"
                )
                print("âœ… è…¾è®¯æ··å…ƒ LLM åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âŒ è…¾è®¯æ··å…ƒåˆå§‹åŒ–å¤±è´¥: {str(e)}")
                print("ğŸ”„ åˆ‡æ¢åˆ° Mock æ¨¡å¼")
                llm_provider = "mock"
                llm = None
    
    elif llm_provider == "openai":
        # ä½¿ç”¨ OpenAI
        llm = ChatOpenAI(
            api_key=api_key or "dummy",
            base_url=base_url,
            model=model_name,
            temperature=0.7
        )
        print("âœ… OpenAI LLM åˆå§‹åŒ–æˆåŠŸ")
    
    elif llm_provider == "mock":
        llm = None
        print("âœ… ä½¿ç”¨ Mock æ¨¡å¼ï¼ˆæµ‹è¯•ç”¨ï¼‰")
    
    return CompleteLifeOSWorkflow(
        llm=llm,
        db_path=db_path,
        enable_conversation_memory=True
    )
